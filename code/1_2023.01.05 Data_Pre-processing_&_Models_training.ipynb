{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c5fd21",
   "metadata": {},
   "source": [
    "# SNF Network-based credit risk models in P2P lending markets\n",
    "Goal: See whether the predictive accuracy of the ML or DL models improve when we include the centrality parameters. So its about checking the AUC values on models trained with and without the centrality measures.\n",
    "\n",
    "Run section 1-6, and go directly to section 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a338255",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3ef1e",
   "metadata": {},
   "source": [
    "## Install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33211d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:31.681552Z",
     "start_time": "2023-06-29T18:34:31.676875Z"
    }
   },
   "outputs": [],
   "source": [
    "def install_missing_packages(package_names):\n",
    "    \"\"\"\n",
    "    Install Missing Packages\n",
    "\n",
    "    This function checks if a list of packages is already installed and installs any missing packages using pip.\n",
    "\n",
    "    Parameters:\n",
    "    - package_names (list): A list of package names to be installed.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    Note: This function requires the `subprocess` and `importlib` modules to be imported.\n",
    "\n",
    "    Example Usage:\n",
    "    install_missing_packages(['h2o', 'numpy', 'pandas'])\n",
    "    \"\"\"\n",
    "    import importlib\n",
    "    import subprocess\n",
    "\n",
    "\n",
    "    for package_name in package_names:\n",
    "        try:\n",
    "            importlib.import_mo``dule(package_name)\n",
    "            print(f\"{package_name} package is already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"{package_name} package not found, installing with pip...\")\n",
    "            subprocess.call(['pip', 'install', package_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ec1e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:32.401606Z",
     "start_time": "2023-06-29T18:34:32.168577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2o package is already installed\n"
     ]
    }
   ],
   "source": [
    "package_list = ['h2o']\n",
    "install_missing_packages(package_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b1afe",
   "metadata": {},
   "source": [
    "## General packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5a649b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:34.333919Z",
     "start_time": "2023-06-29T18:34:33.578928Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, roc_curve, auc,\n",
    "                             precision_recall_curve, average_precision_score)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ca0ae",
   "metadata": {},
   "source": [
    "## h2o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcfe6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:34.604607Z",
     "start_time": "2023-06-29T18:34:34.601569Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "H2O Models\n",
    "\n",
    "This module provides a set of utility functions for working with H2O models. H2O is an open-source machine learning platform that provides a distributed environment for building and deploying machine learning models.\n",
    "\n",
    "Functions:\n",
    "- load_model(model_path): Load an H2O model from the specified path and return the model object.\n",
    "- save_model(model, model_path): Save the given H2O model to the specified path.\n",
    "- predict(model, data): Generate predictions using the specified H2O model on the given data.\n",
    "- evaluate(model, data): Evaluate the performance of the specified H2O model on the given data and return relevant metrics.\n",
    "- get_model_details(model): Get detailed information about the specified H2O model, including its parameters and performance statistics.\n",
    "- get_feature_importance(model): Get the feature importance scores for the specified H2O model, indicating the importance of each feature in the model's predictions.\n",
    "\n",
    "Note: These functions require the H2O Python library to be installed and imported.\n",
    "\n",
    "For more information on H2O, visit the official documentation at https://docs.h2o.ai/.\n",
    "\"\"\"\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator, H2ODeepLearningEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "import h2o.estimators.glm\n",
    "from h2o.estimators import H2OXGBoostEstimator, H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443cac3e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a217d05",
   "metadata": {},
   "source": [
    "## Read and write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165778c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:36.104879Z",
     "start_time": "2023-06-29T18:34:36.099845Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_h2o_frame(directory, file_name):\n",
    "    \"\"\"\n",
    "    Given a directory name and a file name, returns an H2OFrame containing the data from the file.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The name of the directory to search in.\n",
    "        file_name (str): The name of the file to read.\n",
    "\n",
    "    Returns:\n",
    "        H2OFrame: An H2OFrame containing the data from the file.\n",
    "\n",
    "    Example:\n",
    "        >>> directory = 'data'\n",
    "        >>> file_name = 'example.txt'\n",
    "        >>> data = read_h2o_frame(directory, file_name)\n",
    "        >>> type(data)\n",
    "        <class 'h2o.frame.H2OFrame'>\n",
    "    \"\"\"\n",
    "    # navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    \n",
    "    # navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "    \n",
    "    # merge directory path with file name\n",
    "    file_path = os.path.join(dir_path, file_name)\n",
    "    \n",
    "    # import file using h2o\n",
    "    data = h2o.import_file(file_path)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306d0db1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:36.818603Z",
     "start_time": "2023-06-29T18:34:36.807933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finished successfully\n"
     ]
    }
   ],
   "source": [
    "def write_df_to_disk(dataframe, directory, filename, parameters):\n",
    "    \"\"\"\n",
    "    Given a Pandas DataFrame, a directory name, a file name, and a list of parameters,\n",
    "    writes the DataFrame to a file with a name that includes the parameters and returns the full path to the file.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): The DataFrame to write to disk.\n",
    "        directory (str): The name of the directory to write the file in.\n",
    "        filename (str): The name of the file to write.\n",
    "        parameters (list): A list of parameters to include in the filename.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the file that was written.\n",
    "\n",
    "    Example:\n",
    "        >>> df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "        >>> directory = 'data'\n",
    "        >>> filename = 'example.csv'\n",
    "        >>> parameters = ['param1', 'param2']\n",
    "        >>> file_path = write_df_to_disk(df, directory, filename, parameters)\n",
    "        >>> df_loaded = pd.read_csv(file_path)\n",
    "        >>> pd.testing.assert_frame_equal(df, df_loaded)\n",
    "    \"\"\"\n",
    "    # navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    \n",
    "    # navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "\n",
    "    # create directory if it does not exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # merge directory path with file name\n",
    "    file_path = os.path.join(dir_path, parameters+\"_\"+ filename)\n",
    "    \n",
    "    # write dataframe to file\n",
    "    dataframe.to_csv(file_path, index=False)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "def test_write_df_to_disk():\n",
    "    # create example dataframe\n",
    "    df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "    \n",
    "    # write dataframe to disk\n",
    "    directory = 'data'\n",
    "    filename = 'example.csv'\n",
    "    parameters = str('param1'+ 'param2')\n",
    "    file_path = write_df_to_disk(df, directory, filename, parameters)\n",
    "    \n",
    "    # load dataframe from file\n",
    "    df_loaded = pd.read_csv(file_path)\n",
    "    \n",
    "    # check that data before and after writing to disk are the same\n",
    "    pd.testing.assert_frame_equal(df, df_loaded)\n",
    "    print(\"Test finished successfully\")\n",
    "\n",
    "test_write_df_to_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b395e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:37.391286Z",
     "start_time": "2023-06-29T18:34:37.385689Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_list_to_disk(lst, directory, filename, parameters):\n",
    "    \"\"\"\n",
    "    Given a list, a directory name, a file name, and a list of parameters,\n",
    "    writes the list to a file with a name that includes the parameters and returns the full path to the file.\n",
    "\n",
    "    Args:\n",
    "        lst (list): The list to write to disk.\n",
    "        directory (str): The name of the directory to write the file in.\n",
    "        filename (str): The name of the file to write.\n",
    "        parameters (list): A list of parameters to include in the filename.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the file that was written.\n",
    "    \"\"\"\n",
    "    # Navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "    # Navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "\n",
    "    # Create directory if it does not exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Merge directory path with file name, including parameters in the file name\n",
    "    file_path = os.path.join(dir_path, \"_\".join(parameters) + \"_\" + filename)\n",
    "\n",
    "    # Write the list to a file\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in lst:\n",
    "            f.write(f\"{item}\\n\")\n",
    "\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b39fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:38.204285Z",
     "start_time": "2023-06-29T18:34:38.200649Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_df_from_disk(directory, filename, parameters):\n",
    "    \"\"\"\n",
    "    Given a directory name, a file name, and a list of parameters,\n",
    "    reads the data from the file with the specified name and returns it as a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The name of the directory to read the file from.\n",
    "        filename (str): The name of the file to read.\n",
    "        parameters (list): A list of parameters that were included in the filename.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The data from the file as a Pandas DataFrame.\n",
    "\n",
    "    Example:\n",
    "        >>> directory = 'data'\n",
    "        >>> filename = 'param1_param2_example.csv'\n",
    "        >>> parameters = ['param1', 'param2']\n",
    "        >>> df = read_df_from_disk(directory, filename, parameters)\n",
    "    \"\"\"\n",
    "    # navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    \n",
    "    # navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "    \n",
    "    # merge directory path with file name\n",
    "    file_path = os.path.join(dir_path, parameters + \"_\" + filename)\n",
    "    \n",
    "    # read dataframe from file\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f152b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:38.806910Z",
     "start_time": "2023-06-29T18:34:38.802815Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_list_from_disk(directory, filename, parameters):\n",
    "    \"\"\"\n",
    "    Given a directory name, a file name, and a list of parameters,\n",
    "    reads the data from the file with the specified name and returns it as a list.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The name of the directory to read the file from.\n",
    "        filename (str): The name of the file to read.\n",
    "        parameters (list): A list of parameters that were included in the filename.\n",
    "\n",
    "    Returns:\n",
    "        list: The data from the file as a list.\n",
    "\n",
    "    Example:\n",
    "        >>> directory = 'data'\n",
    "        >>> filename = 'param1_param2_example.txt'\n",
    "        >>> parameters = ['param1', 'param2']\n",
    "        >>> lst = read_list_from_disk(directory, filename, parameters)\n",
    "    \"\"\"\n",
    "    # Navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "    # Navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "\n",
    "    # Merge directory path with file name, including parameters in the file name\n",
    "    file_path = os.path.join(dir_path, \"_\".join(parameters) + \"_\" + filename)\n",
    "\n",
    "    # Read list from file\n",
    "    with open(file_path, 'r') as f:\n",
    "        lst = [line.strip() for line in f]\n",
    "\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7657e8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:39.444609Z",
     "start_time": "2023-06-29T18:34:39.440282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\n"
     ]
    }
   ],
   "source": [
    "def calculate_hash(string):\n",
    "    \"\"\"Calculate SHA-256 hash of a given string\"\"\"\n",
    "    hash_object = hashlib.sha256(string.encode())\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return hex_dig\n",
    "hash_result = calculate_hash(\"hello world\")\n",
    "print(hash_result)\n",
    "# Output:  b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7e504",
   "metadata": {},
   "source": [
    "## H20 \n",
    "related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ac0f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:40.419246Z",
     "start_time": "2023-06-29T18:34:40.415002Z"
    }
   },
   "outputs": [],
   "source": [
    "def pandas_to_h2o(data):\n",
    "    # Convert Pandas DataFrame to H2OFrame\n",
    "    h2o_df = h2o.H2OFrame(data)\n",
    "    return h2o_df\n",
    "\n",
    "def h2o_to_pandas(h2o_df):\n",
    "    # Convert H2OFrame to Pandas DataFrame\n",
    "    pandas_df = h2o_df.as_data_frame()\n",
    "\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b16faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:41.007134Z",
     "start_time": "2023-06-29T18:34:41.003320Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_binary_continuous_columns(data: pd.DataFrame, target_column: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Identify binary and continuous columns in a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): The input Pandas DataFrame.\n",
    "    target_column (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple of two lists containing the binary and continuous columns, respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    binary_columns = []\n",
    "    continuous_columns = []\n",
    "\n",
    "    for column in data.columns:\n",
    "        if column != target_column:\n",
    "            unique_values = len(data[column].unique())\n",
    "            if unique_values == 2:\n",
    "                binary_columns.append(column)\n",
    "            else:\n",
    "                continuous_columns.append(column)\n",
    "\n",
    "    return binary_columns, continuous_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a66ab7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:41.616631Z",
     "start_time": "2023-06-29T18:34:41.613276Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_binary_to_categorical(data, binary_columns):\n",
    "    \"\"\"\n",
    "    Convert binary columns in a DataFrame to categorical data type.\n",
    "\n",
    "    :param data: A pandas DataFrame containing the data.\n",
    "    :param binary_columns: A list of column names that are binary.\n",
    "    :return: A new pandas DataFrame with binary columns converted to categorical data type.\n",
    "    \"\"\"\n",
    "    data_categorical = data.copy()\n",
    "\n",
    "    for column in binary_columns:\n",
    "        data_categorical[column] = data_categorical[column].astype('category')\n",
    "\n",
    "    return data_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216d0805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:42.157511Z",
     "start_time": "2023-06-29T18:34:42.153806Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_h2o_frame(pandas_data,binary_columns):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame or Series to an H2O Frame, preserving categorical columns.\n",
    "\n",
    "    :param pandas_data: pandas DataFrame or Series to be converted\n",
    "    :return: Converted H2O Frame\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pandas Series to DataFrame\n",
    "    if isinstance(pandas_data, pd.Series):\n",
    "        pandas_data = pandas_data.to_frame()\n",
    "\n",
    "    # Convert pandas DataFrame to H2O Frame\n",
    "    h2o_frame = h2o.H2OFrame(pandas_data)\n",
    "\n",
    "    # Set factor levels for categorical columns in the H2O Frame\n",
    "    for column in h2o_frame.columns:\n",
    "        if column in binary_columns:\n",
    "            h2o_frame[column] = h2o_frame[column].asfactor()\n",
    "\n",
    "    return h2o_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6dc6625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:42.674171Z",
     "start_time": "2023-06-29T18:34:42.670706Z"
    }
   },
   "outputs": [],
   "source": [
    "def exclude_columns(data: pd.DataFrame, exclude_list: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Exclude specified columns from a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): The input Pandas DataFrame.\n",
    "    exclude_list (list): The list of column names to exclude.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A new DataFrame with the specified columns removed.\n",
    "\n",
    "    \"\"\"\n",
    "    new_data = data.drop(exclude_list, axis=1)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e1bb87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:43.192581Z",
     "start_time": "2023-06-29T18:34:43.188268Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_classification_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and print binary classification metrics: accuracy, confusion matrix, and classification report.\n",
    "    \n",
    "    :param y_true: A pandas DataFrame or Series containing the true target values.\n",
    "    :param y_pred: A pandas DataFrame or Series containing the predicted target values.\n",
    "    :return: A dictionary containing the calculated classification metrics.\n",
    "    \"\"\"\n",
    "    # Calculate classification metrics\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
    "    metrics['classification_report'] = classification_report(y_true, y_pred)\n",
    "    \n",
    "    # Print the classification metrics\n",
    "    print('Accuracy:', metrics['accuracy'])\n",
    "    print('Confusion Matrix:\\n', metrics['confusion_matrix'])\n",
    "    print('Classification Report:\\n', metrics['classification_report'])\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0face55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:43.731861Z",
     "start_time": "2023-06-29T18:34:43.725421Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true,\n",
    "                         y_pred,\n",
    "                         positive_class=1,\n",
    "                         roc_file='roc_plot.html',\n",
    "                         pr_file='pr_plot.html'):\n",
    "    \"\"\"\n",
    "    Evaluate classification metrics, plot ROC curve and Precision-Recall curve using Plotly, and save plots as HTML files.\n",
    "\n",
    "    :param y_true: A pandas DataFrame or Series containing the true target values.\n",
    "    :param y_pred: A pandas DataFrame or Series containing the predicted target values.\n",
    "    :param positive_class: The label of the positive class (default: 1).\n",
    "    :param roc_file: The name of the HTML file to save the ROC curve plot (default: 'roc_plot.html').\n",
    "    :param pr_file: The name of the HTML file to save the Precision-Recall curve plot (default: 'pr_plot.html').\n",
    "    :return: A dictionary containing various classification metrics.\n",
    "    \"\"\"\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred, pos_label=positive_class)\n",
    "    metrics['auc'] = auc(fpr, tpr)\n",
    "\n",
    "    # Calculate Precision-Recall curve and average precision\n",
    "    precision, recall, _ = precision_recall_curve(y_true,\n",
    "                                                  y_pred,\n",
    "                                                  pos_label=positive_class)\n",
    "    metrics['average_precision'] = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    # Create ROC curve plot\n",
    "    fig_roc = make_subplots(rows=1, cols=1, subplot_titles=('ROC Curve', ))\n",
    "    fig_roc.add_trace(go.Scatter(x=fpr,\n",
    "                                 y=tpr,\n",
    "                                 mode='lines',\n",
    "                                 name='ROC Curve',\n",
    "                                 line=dict(color='blue')),\n",
    "                      row=1,\n",
    "                      col=1)\n",
    "    fig_roc.add_trace(go.Scatter(x=[0, 1],\n",
    "                                 y=[0, 1],\n",
    "                                 mode='lines',\n",
    "                                 name='Random',\n",
    "                                 line=dict(color='black', dash='dash')),\n",
    "                      row=1,\n",
    "                      col=1)\n",
    "    fig_roc.update_layout(title=f'ROC Curve (AUC = {metrics[\"auc\"]:.4f})',\n",
    "                          xaxis_title='False Positive Rate',\n",
    "                          yaxis_title='True Positive Rate',\n",
    "                          showlegend=True,\n",
    "                          legend=dict(orientation='h',\n",
    "                                      yanchor='bottom',\n",
    "                                      xanchor='right',\n",
    "                                      y=1.02,\n",
    "                                      x=1))\n",
    "\n",
    "    # Save the ROC curve plot as an HTML file\n",
    "    pio.write_html(fig_roc, file=roc_file)\n",
    "\n",
    "    # Create Precision-Recall curve plot\n",
    "    fig_pr = make_subplots(rows=1,\n",
    "                           cols=1,\n",
    "                           subplot_titles=('Precision-Recall Curve', ))\n",
    "    fig_pr.add_trace(go.Scatter(x=recall,\n",
    "                                y=precision,\n",
    "                                mode='lines',\n",
    "                                name='Precision-Recall Curve',\n",
    "                                line=dict(color='blue')),\n",
    "                     row=1,\n",
    "                     col=1)\n",
    "    fig_pr.update_layout(\n",
    "        title=\n",
    "        f'Precision-Recall Curve (Avg. Precision = {metrics[\"average_precision\"]:.4f})',\n",
    "        xaxis_title='Recall',\n",
    "        yaxis_title='Precision',\n",
    "        showlegend=True,\n",
    "        legend=dict(orientation='h',\n",
    "                    yanchor='bottom',\n",
    "                    xanchor='right',\n",
    "                    y=1.02,\n",
    "                    x=1))\n",
    "\n",
    "    # Save the Precision-Recall curve plot as an HTML file\n",
    "    pio.write_html(fig_pr, file=pr_file)\n",
    "\n",
    "    # Print classification metrics nicely\n",
    "\n",
    "    print(f'AUC: {metrics[\"auc\"]:.4f}')\n",
    "    print(f'Average Precision: {metrics[\"average_precision\"]:.4f}')\n",
    "\n",
    "    # Open the HTML files in the default web browser\n",
    "    webbrowser.open(roc_file)\n",
    "    webbrowser.open(pr_file)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "858e6594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:44.327039Z",
     "start_time": "2023-06-29T18:34:44.322597Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_h2o_model_to_disk(model, directory, filename, run_explanation=False, force_return=True):\n",
    "    \"\"\"\n",
    "    Given an H2O estimator object, a directory name, and a file name,\n",
    "    saves the trained model to disk using the provided file name and directory.\n",
    "    If 'force_rerun' is set to True, it will delete any existing model at the \n",
    "    specified path before saving the new model. If 'run_explanation' is set to True,\n",
    "    it will generate and save an explanation of the model.\n",
    "\n",
    "    Args:\n",
    "        model (H2OEstimator): The H2O estimator object to save.\n",
    "        directory (str): The name of the directory to save the model in.\n",
    "        filename (str): The name of the file to save the model in.\n",
    "        run_explanation (bool, optional): Whether to generate and save an explanation \n",
    "            of the model. Defaults to False.\n",
    "        force_rerun (bool, optional): Whether to delete any existing model at the \n",
    "            specified path before saving the new model. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the saved model.\n",
    "\n",
    "    Example:\n",
    "        >>> model = h2o.estimators.random_forest.H2ORandomForestEstimator(ntrees=50, max_depth=20, nfolds=10, seed=42)\n",
    "        >>> data = h2o.import_file('example.csv')\n",
    "        >>> predictors = ['a', 'b']\n",
    "        >>> response = 'c'\n",
    "        >>> model.train(x=predictors, y=response, training_frame=data)\n",
    "        >>> directory = 'models'\n",
    "        >>> filename = 'rf_model'\n",
    "        >>> saved_model_path = save_h2o_model_to_disk(model, directory, filename)\n",
    "        >>> loaded_model = h2o.load_model(saved_model_path)\n",
    "    \"\"\"\n",
    "    # navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "    # navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "\n",
    "    # create directory if it does not exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # merge directory path with file name\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "\n",
    "\n",
    "    if force_return and os.path.exists(file_path):\n",
    "        shutil.rmtree(file_path)\n",
    "    # save model to file\n",
    "    #model.save_model(file_path)\n",
    "    h2o.save_model(model, file_path)\n",
    "    \n",
    "    if(run_explanation):\n",
    "        explanation = h2o.explain(model, frame=None, figsize=(12, 8), render=False)\n",
    "        \n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51c59f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:45.200904Z",
     "start_time": "2023-06-29T18:34:45.196511Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_h2o_explanation_to_disk(explanation, directory, model_filename, explanation_filename):\n",
    "    \"\"\"\n",
    "    Given an H2O estimator object, a directory name, and file names for the model and explanation,\n",
    "    saves the trained model and its explanation to disk using the provided file names and directory.\n",
    "\n",
    "    Args:\n",
    "        model (H2OEstimator): The H2O estimator object to save.\n",
    "        directory (str): The name of the directory to save the model and explanation in.\n",
    "        model_filename (str): The name of the file to save the model in.\n",
    "        explanation_filename (str): The name of the file to save the explanation in.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The full paths to the saved model and explanation.\n",
    "\n",
    "    Example:\n",
    "        >>> model = h2o.estimators.random_forest.H2ORandomForestEstimator(ntrees=50, max_depth=20, nfolds=10, seed=42)\n",
    "        >>> data = h2o.import_file('example.csv')\n",
    "        >>> predictors = ['a', 'b']\n",
    "        >>> response = 'c'\n",
    "        >>> model.train(x=predictors, y=response, training_frame=data)\n",
    "        >>> directory = 'models'\n",
    "        >>> model_filename = 'rf_model'\n",
    "        >>> explanation_filename = 'rf_explanation.html'\n",
    "        >>> saved_model_path, saved_explanation_path = save_h2o_model_and_explanation_to_disk(model, directory, model_filename, explanation_filename)\n",
    "        >>> loaded_model = h2o.load_model(saved_model_path)\n",
    "    \"\"\"\n",
    "    # navigate up one level from cwd\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "    # navigate into directory\n",
    "    dir_path = os.path.join(parent_dir, directory)\n",
    "\n",
    "    # create directory if it does not exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # merge directory path with file names\n",
    "    model_file_path = os.path.join(dir_path, model_filename)\n",
    "    explanation_file_path = os.path.join(dir_path, explanation_filename)\n",
    "\n",
    "    with open(explanation_file_path, 'w') as f:\n",
    "        f.write(explanation)\n",
    "\n",
    "    # save explanation plots to files\n",
    "    for i, item in enumerate(explanation):\n",
    "        if isinstance(item, plt.Figure):\n",
    "            item.savefig(os.path.join(explanation_file_path, f\"plot_{i}.png\"))\n",
    "            plt.close(item)\n",
    "\n",
    "    return model_file_path, explanation_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057fdb6",
   "metadata": {},
   "source": [
    "## Model training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d9b154d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:46.367775Z",
     "start_time": "2023-06-29T18:34:46.362985Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_file_path(file_name):\n",
    "    \"\"\"\n",
    "    Generate a file path for a file located one directory level up.\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): The name of the file including any subdirectories from the parent directory.\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): The full path to the file.\n",
    "    \"\"\"\n",
    "    # Get the current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Get the parent directory\n",
    "    parent_dir = os.path.dirname(cwd)\n",
    "\n",
    "    # Define the file path by joining the parent directory path with the file name\n",
    "    file_path = os.path.join(parent_dir, file_name)\n",
    "\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a16605c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:47.174585Z",
     "start_time": "2023-06-29T18:34:47.161729Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def model_training_and_saving(X_train,\n",
    "                              X_val,\n",
    "                              y_train,\n",
    "                              y_val,\n",
    "                              exclude_LIST,\n",
    "                              models_and_hyperparams,\n",
    "                              model_to_train,\n",
    "                              model_directory,\n",
    "                              run_explanation,\n",
    "                              output_filepath=None,\n",
    "                              print_training_info=False,\n",
    "                              force_return=True):\n",
    "    \"\"\"\n",
    "    Train models specified in 'models_and_hyperparams' using H2O Grid Search with given training data.\n",
    "    Save the trained model to disk. If 'force_rerun' is set to True, it will delete any existing \n",
    "    model before retraining and saving the new model. If 'run_explanation' is set to True, it will\n",
    "    generate and save an explanation of the model.\n",
    "\n",
    "    Args:\n",
    "        X_train (DataFrame): The training data to use for model training.\n",
    "        exclude_list (list): List of feature names to be excluded from the training.\n",
    "        y_train (DataFrame): The target variables for model training.\n",
    "        data_set_parameters (str): Information that uniquely describes the dataset.\n",
    "        models_and_hyperparams (list of dict): List of dictionaries, where each dictionary contains \n",
    "            information about a model and its hyperparameters to be trained.\n",
    "        model_to_train (str): Model to be trained this time.\n",
    "        model_directory (str): The directory where the trained model will be saved.\n",
    "        run_explanation (bool, optional): Whether to generate and save an explanation of the model. Defaults to False.\n",
    "        force_rerun (bool, optional): Whether to delete any existing model before retraining and saving the new model. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if output_filepath and isinstance(output_filepath, str):\n",
    "        output_directory = os.path.dirname(output_filepath)  # 获取输出文件所在的目录路径\n",
    "\n",
    "        # 如果目录不存在，则创建它\n",
    "        if output_directory and not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        try:\n",
    "            output_file = open(output_filepath, 'w')\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            output_file = open(output_filepath, 'w')\n",
    "\n",
    "    else:\n",
    "        output_file = output_filepath  # 直接使用提供的文件对象\n",
    "\n",
    "    # 为每个模型和超参数组合执行Grid Search\n",
    "    for model_info in models_and_hyperparams:  ##loop: model type\n",
    "        modelName = model_info['model']\n",
    "\n",
    "        if model_mapping[modelName] not in model_to_train:\n",
    "            continue  # the model has parameters but you do not want to train it this time\n",
    "\n",
    "        seen = set(\n",
    "        )  #To avoid repeated exclude_list. They are necessary in follwing code, but should be avoided here.\n",
    "\n",
    "        #print some info\n",
    "        print(f'Model info: {model_info}\\n', file=output_file)  # 打印模型信息\n",
    "\n",
    "        for exclude_list in exclude_LIST:  ##loop: train set\n",
    "\n",
    "            print(str(sorted(exclude_list)) + '\\n', file=output_file)\n",
    "\n",
    "            model = model_info['model']\n",
    "\n",
    "            #if this exclude_list has been trained, escape it\n",
    "            exclude_list_tuple = tuple(exclude_list)\n",
    "            if exclude_list_tuple in seen:\n",
    "                continue\n",
    "            else:\n",
    "                seen.add(exclude_list_tuple)\n",
    "\n",
    "            #predictors\n",
    "            included_features = [\n",
    "                col for col in X_train.columns if col not in exclude_list\n",
    "            ]\n",
    "\n",
    "            model_name = model_info['model_name']\n",
    "\n",
    "            # 初始化Grid Search\n",
    "            params = model_info.get('params', {})\n",
    "            hyper_params = model_info['hyper_params']\n",
    "\n",
    "            grid = H2OGridSearch(model=model(**params),\n",
    "                                 hyper_params=hyper_params,\n",
    "                                 search_criteria={\"strategy\": \"Cartesian\"})\n",
    "            # 训练多个模型\n",
    "            grid.train(x=included_features,\n",
    "                       y=y_train.columns,\n",
    "                       training_frame=X_train.cbind(y_train),\n",
    "                       validation_frame=X_val.cbind(y_val))  # 使用验证集\n",
    "\n",
    "            # 获取Grid Search结果\n",
    "            grid_results = grid.get_grid()\n",
    "\n",
    "            keys, values = zip(*hyper_params.items())\n",
    "            hyper_param_combinations = [\n",
    "                dict(zip(keys, v)) for v in itertools.product(*values)\n",
    "            ]\n",
    "\n",
    "            metric_table = grid_results.sorted_metric_table()\n",
    "\n",
    "            best_auc = 0  # 初始化最优AUC值\n",
    "            best_hyper_params = None  # 初始化最优超参数\n",
    "            best_model_id = None  #model id for the best model under same exclude_liat\n",
    "\n",
    "            for i, hyper_param in enumerate(\n",
    "                    hyper_param_combinations):  #loop: para\n",
    "\n",
    "                indices = list(range(len(metric_table)))\n",
    "                for key in list(hyper_param.keys()):\n",
    "                    indices_new = [\n",
    "                        i for i, value in enumerate(metric_table[key].tolist())\n",
    "                        if (str(value) == str(hyper_param[key])\n",
    "                            or value == str(hyper_param[key]) or str(value) ==\n",
    "                            hyper_param[key] or value == hyper_param[key])\n",
    "                    ]\n",
    "                    indices = [\n",
    "                        value for value in indices_new if value in indices\n",
    "                    ]\n",
    "\n",
    "                model_id = metric_table['model_ids'].tolist()[indices[0]]\n",
    "                model = h2o.get_model(model_id)\n",
    "                model_to_save = h2o.get_model(model_id)\n",
    "\n",
    "                # 获取模型在验证集上的AUC\n",
    "                model_perf = model.model_performance(X_val.cbind(y_val))\n",
    "                model_auc = model_perf.auc()\n",
    "\n",
    "                data_set_parameters = str(\n",
    "                    sorted(exclude_list)\n",
    "                ) + data_directory + preprocessed_filename + file_name\n",
    "                # for saving trained model to disk. # those are the parameters that uniquely describe the dataset\n",
    "                model_parameters = data_set_parameters + model_name + str(\n",
    "                    hyper_param)  #\n",
    "                model_parameters_hash = calculate_hash(model_parameters)\n",
    "\n",
    "                model_to_save.model_id = model_parameters_hash\n",
    "\n",
    "                save_h2o_model_to_disk(model=model_to_save,\n",
    "                                       directory=model_directory,\n",
    "                                       filename=model_parameters_hash,\n",
    "                                       force_return=force_return)\n",
    "\n",
    "                if model_auc > best_auc:\n",
    "                    best_auc = model_auc\n",
    "                    best_hyper_params = hyper_param\n",
    "                    best_model_id = model_to_save.model_id\n",
    "\n",
    "                # print some information\n",
    "                if print_training_info:\n",
    "                    print(\n",
    "                        f'model_parameters: {model_parameters} model_parameters_hash: {model_parameters_hash} trained and saved!\\n model_parameters_hash: {model_parameters_hash}\\n'\n",
    "                    )\n",
    "\n",
    "                if run_explanation:\n",
    "                    explanation = h2o.explain(model_to_save,\n",
    "                                              frame=X_train.cbind(y_train),\n",
    "                                              figsize=(12, 8),\n",
    "                                              render=False)\n",
    "                    save_h2o_explanation_to_disk(\n",
    "                        explanation=explanation,\n",
    "                        directory=model_directory,\n",
    "                        model_filename=model_parameters_hash,\n",
    "                        explanation_filename='explain')\n",
    "            print(f'Best hyper parameters: {best_hyper_params}\\n',\n",
    "                  file=output_file)\n",
    "            print(f'Best model id: {best_model_id}\\n\\n',file=output_file)\n",
    "\n",
    "    # 在打印完成后，如果输出文件是通过字符串指定的，则关闭文件\n",
    "    if isinstance(output_filepath, str):\n",
    "        output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62711cd",
   "metadata": {},
   "source": [
    "## Shuffle columns in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37846a2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:49.950390Z",
     "start_time": "2023-06-29T18:34:49.943738Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_columns(df, columns):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame and a list of column names, and returns a new DataFrame\n",
    "    where the rows in each of the specified columns have been randomly shuffled.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.core.frame.DataFrame): The original DataFrame.\n",
    "    columns (list): A list of column names to be shuffled.\n",
    "\n",
    "    Returns:\n",
    "    pandas.core.frame.DataFrame: A new DataFrame with the specified columns shuffled.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If any of the specified column names do not exist in the DataFrame.\n",
    "    \"\"\"\n",
    "    # First, we will check if all columns exist in the DataFrame\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column {col} does not exist in the DataFrame\")\n",
    "\n",
    "    # Create a copy of the DataFrame so that the original DataFrame remains unmodified\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # For each specified column, shuffle the rows\n",
    "    for col in columns:\n",
    "        df_copy[col] = df[col].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b1378",
   "metadata": {},
   "source": [
    "## Functions for feature selcetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a785159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:51.067769Z",
     "start_time": "2023-06-29T18:34:50.918037Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import h2o\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(df, file, column=None):\n",
    "    \"\"\"\n",
    "    For each column, plot a histogram.\n",
    "    If the column is full of NaN values, print a warning and skip it.\n",
    "    Save each histogram as a separate page in the PDF specified by `file`.\n",
    "    Also compute and display the mean, variance, and standard deviation of each column.\n",
    "\n",
    "    Args:\n",
    "    df: h2o frame. The H2OFrame to plot from.\n",
    "    file: string. The path to the output PDF file.\n",
    "    column: string, optional. The column to plot. If not provided, plot all columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the H2OFrame to pandas DataFrame for plotting\n",
    "    df = df.as_data_frame()\n",
    "\n",
    "    with PdfPages(file) as pdf: # Output to PDF\n",
    "        if column:  # If a column is specified, only plot this column\n",
    "            cols = [column]\n",
    "        else:  # If no column is specified, plot all columns\n",
    "            cols = df.columns\n",
    "\n",
    "        for col in cols:\n",
    "            if df[col].isna().all(): # If column is full of NaN values, print a warning and skip it\n",
    "                print(f\"Warning: Column {col} only contains NaN values. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            plt.figure()\n",
    "            df_no_nan = df[col].dropna() # Remove NaN values for calculation and plotting\n",
    "            sns.histplot(df_no_nan, kde=False, bins=50) # Limit the number of bins to 50\n",
    "            plt.title(f\"Histogram of {col}\")\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "            # Calculate mean, variance and standard deviation, and display them on the histogram\n",
    "            mean = np.mean(df_no_nan)\n",
    "            var = np.var(df_no_nan)\n",
    "            std = np.std(df_no_nan)\n",
    "            stats_text = f\"Mean: {mean:.2f}\\nVariance: {var:.2f}\\nStd Dev: {std:.2f}\"\n",
    "            plt.annotate(stats_text, xy=(0.95, 0.95), xycoords='axes fraction', horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "            pdf.savefig()  # Save the current figure to the PDF\n",
    "            plt.close()  # Close the current figure\n",
    "\n",
    "# Example usage:\n",
    "# centrality_data_path = generate_file_path(\"graph/Bondora_centrality_sample(\"+str(num_default_samples*2)+\").pdf\")\n",
    "# plot_histogram(centrality_df, centrality_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ad7925f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:51.466614Z",
     "start_time": "2023-06-29T18:34:51.440293Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "\n",
    "def exclude_feature(X, y):\n",
    "    \"\"\"\n",
    "    Feature selection function. Takes an H2OFrame, X and y, and returns a list\n",
    "    of features to be excluded from training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert H2OFrame to pandas DataFrame for feature selection\n",
    "    X_pd = X.as_data_frame(use_pandas=True)\n",
    "    y_pd = y.as_data_frame(use_pandas=True)\n",
    "\n",
    "    # Exclude columns with all NaN values or any NaN values\n",
    "    exclude_columns = [col for col in X_pd.columns if X_pd[col].isnull().all() or X_pd[col].isnull().any()]\n",
    "    \n",
    "    # Exclude constant or quasi-constant features\n",
    "    X_no_nan = X_pd.drop(columns=exclude_columns)  # remove the NaN columns for the following steps\n",
    "    constant_filter = VarianceThreshold(threshold=0.005)\n",
    "    constant_filter.fit(X_no_nan)\n",
    "    constant_columns = [column for column in X_no_nan.columns\n",
    "                        if column not in X_no_nan.columns[constant_filter.get_support()]]\n",
    "    exclude_columns.extend(constant_columns)\n",
    "\n",
    "    # Exclude correlated features\n",
    "    correlated_features = set()\n",
    "    correlation_matrix = X_no_nan.corr()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    exclude_columns.extend(correlated_features)\n",
    "\n",
    "    # Feature selection using SelectKBest\n",
    "    X_nonnegative = MinMaxScaler().fit_transform(X_no_nan)\n",
    "    selector = SelectKBest(score_func=chi2, k=140)  # Choose k as per your requirements\n",
    "    selector.fit(X_nonnegative, y_pd)\n",
    "    low_score_features = [column for column in X_no_nan.columns\n",
    "                          if column not in X_no_nan.columns[selector.get_support()]]\n",
    "    exclude_columns.extend(low_score_features)\n",
    "\n",
    "    return exclude_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bb626",
   "metadata": {},
   "source": [
    "# Parameters 1: Parameters for data pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e07185f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:52.580822Z",
     "start_time": "2023-06-29T18:34:52.577230Z"
    }
   },
   "outputs": [],
   "source": [
    "## data parameters\n",
    "data_directory = \"data\"  # where the data is stored\n",
    "preprocessed_filename = \"preprocessed\"  # filename we give for storing the preprocessed data, just before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8303ad11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:52.911656Z",
     "start_time": "2023-06-29T18:34:52.908702Z"
    }
   },
   "outputs": [],
   "source": [
    "# filename we give for storing the preprocessed data, just before training\n",
    "preprocessed_filename = \"preprocessed_shuffled\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cd0fe9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:53.448912Z",
     "start_time": "2023-06-29T18:34:53.446038Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = 'data'\n",
    "file_name = 'Bondora_sample(24000)_with_centrality.csv'\n",
    "parameter_string = \"pandas_washes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d1b18",
   "metadata": {},
   "source": [
    "# Auto ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ee6c7",
   "metadata": {},
   "source": [
    "## Init H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d6ab33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:55.129930Z",
     "start_time": "2023-06-29T18:34:55.037692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 3 hours 36 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Zurich</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 1 day</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_yil1_hs16ns</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>6.168 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.17 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 day 3 hours 36 mins\n",
       "H2O_cluster_timezone:       Europe/Zurich\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    2 months and 1 day\n",
       "H2O_cluster_name:           H2O_from_python_yil1_hs16ns\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    6.168 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.17 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import the necessary libraries and start the H2O cluster:\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a375e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40293175",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829e8d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:58.164690Z",
     "start_time": "2023-06-29T18:34:56.738925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "<class 'h2o.frame.H2OFrame'>\n"
     ]
    }
   ],
   "source": [
    "# read data from file using H2O\n",
    "data_all_features = read_h2o_frame(directory, file_name)\n",
    "# print data type\n",
    "print(type(data_all_features))  # <class 'h2o.frame.H2OFrame'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a54007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:01.085633Z",
     "start_time": "2023-06-29T18:35:00.570049Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "data_all_features = h2o_to_pandas(data_all_features)\n",
    "#We wash data in the pandas dataframe, then convert it back to the h2o frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c5d6e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:01.238567Z",
     "start_time": "2023-06-29T18:35:01.227007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>new</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Interest</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>DebtToIncome</th>\n",
       "      <th>NoOfPreviousLoansBeforeLoan</th>\n",
       "      <th>AmountOfPreviousLoansBeforeLoan</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>19.33</td>\n",
       "      <td>5.284117</td>\n",
       "      <td>58.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.670</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.902073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078653e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>16.23</td>\n",
       "      <td>5.241324</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.976149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.410830e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>13.34</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>43.85</td>\n",
       "      <td>4</td>\n",
       "      <td>12200.0</td>\n",
       "      <td>2.938</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.396533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.701703e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>23.32</td>\n",
       "      <td>3.161247</td>\n",
       "      <td>7.58</td>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.505</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.359868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.883548e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>18.45</td>\n",
       "      <td>4.771532</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.029100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.762067e-95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  new  Age  Gender  Interest  MonthlyPayment  DebtToIncome  \\\n",
       "0        0    1   51       0     19.33        5.284117         58.48   \n",
       "1        0    1   28       0     16.23        5.241324          0.00   \n",
       "2        0    0   40       0     13.34        4.438525         43.85   \n",
       "3        0    0   25       0     23.32        3.161247          7.58   \n",
       "4        0    1   50       0     18.45        4.771532          0.00   \n",
       "\n",
       "   NoOfPreviousLoansBeforeLoan  AmountOfPreviousLoansBeforeLoan   time  ...  \\\n",
       "0                            0                              0.0  2.670  ...   \n",
       "1                            0                              0.0  4.373  ...   \n",
       "2                            4                          12200.0  2.938  ...   \n",
       "3                            2                           1100.0  2.505  ...   \n",
       "4                            0                              0.0  4.034  ...   \n",
       "\n",
       "   A  B  C  pagerank  betweenness  closeness  eigenvector      katz  \\\n",
       "0  0  0  1  0.000023          0.0   8.902073          NaN  0.006453   \n",
       "1  0  1  0  0.000023          0.0  15.976149          NaN  0.006453   \n",
       "2  0  1  0  0.000023          0.0  13.396533          NaN  0.006453   \n",
       "3  0  0  1  0.000023          0.0   7.359868          NaN  0.006453   \n",
       "4  0  1  0  0.000023          0.0  26.029100          NaN  0.006453   \n",
       "\n",
       "   authority           hub  \n",
       "0        0.0  2.078653e-22  \n",
       "1        0.0  2.410830e-83  \n",
       "2        0.0  6.701703e-47  \n",
       "3        0.0  3.883548e-67  \n",
       "4        0.0  1.762067e-95  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "977d5acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:06.778709Z",
     "start_time": "2023-06-29T18:35:06.773942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['default', 'new', 'Age', 'Gender', 'Interest', 'MonthlyPayment',\n",
       "       'DebtToIncome', 'NoOfPreviousLoansBeforeLoan',\n",
       "       'AmountOfPreviousLoansBeforeLoan', 'time',\n",
       "       ...\n",
       "       'A', 'B', 'C', 'pagerank', 'betweenness', 'closeness', 'eigenvector',\n",
       "       'katz', 'authority', 'hub'],\n",
       "      dtype='object', length=162)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba43fb7",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "use min max scaler.\n",
    "all binary columns to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f3f86",
   "metadata": {},
   "source": [
    "### Identify binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "707608ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:08.627633Z",
     "start_time": "2023-06-29T18:35:08.593045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the binary and continuous columns\n",
    "binary_columns, continuous_columns = identify_binary_continuous_columns(data_all_features, 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3521b8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:09.607293Z",
     "start_time": "2023-06-29T18:35:09.601100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'Gender',\n",
       " 'Hour.0',\n",
       " 'Hour.1',\n",
       " 'Hour.2',\n",
       " 'Hour.3',\n",
       " 'Hour.4',\n",
       " 'Hour.5',\n",
       " 'Hour.6',\n",
       " 'Hour.7',\n",
       " 'Hour.8',\n",
       " 'Hour.9',\n",
       " 'Hour.10',\n",
       " 'Hour.11',\n",
       " 'Hour.12',\n",
       " 'Hour.13',\n",
       " 'Hour.14',\n",
       " 'Hour.15',\n",
       " 'Hour.16',\n",
       " 'Hour.17',\n",
       " 'Hour.18',\n",
       " 'Hour.19',\n",
       " 'Hour.20',\n",
       " 'Hour.21',\n",
       " 'Hour.22',\n",
       " 'weekday.1',\n",
       " 'weekday.2',\n",
       " 'weekday.3',\n",
       " 'weekday.4',\n",
       " 'weekday.5',\n",
       " 'weekday.6',\n",
       " 'ver.3',\n",
       " 'ver.4',\n",
       " 'duration.06',\n",
       " 'duration.09',\n",
       " 'duration.12',\n",
       " 'duration.18',\n",
       " 'duration.24',\n",
       " 'duration.36',\n",
       " 'duration.48',\n",
       " 'duration.60',\n",
       " 'use.0',\n",
       " 'use.1',\n",
       " 'use.2',\n",
       " 'use.3',\n",
       " 'use.4',\n",
       " 'use.5',\n",
       " 'use.6',\n",
       " 'use.7',\n",
       " 'use.8',\n",
       " 'educ.2',\n",
       " 'educ.3',\n",
       " 'educ.4',\n",
       " 'educ.5',\n",
       " 'marital.1',\n",
       " 'marital.2',\n",
       " 'marital.3',\n",
       " 'marital.4',\n",
       " 'marital.5',\n",
       " 'depen.0',\n",
       " 'depen.1',\n",
       " 'depen.2',\n",
       " 'depen.3',\n",
       " 'depen.4',\n",
       " 'employ.2',\n",
       " 'employ.3',\n",
       " 'employ.4',\n",
       " 'employ.5',\n",
       " 'employ.6',\n",
       " 'em.dur.other',\n",
       " 'em.dur.ret',\n",
       " 'em.dur.trial',\n",
       " 'em.dur.1y',\n",
       " 'em.dur.2y',\n",
       " 'em.dur.3y',\n",
       " 'em.dur.4y',\n",
       " 'em.dur.5y',\n",
       " 'exper.02y',\n",
       " 'exper.05y',\n",
       " 'exper.10y',\n",
       " 'exper.15y',\n",
       " 'exper.25y',\n",
       " 'exper.25p',\n",
       " 'Other',\n",
       " 'Processing',\n",
       " 'Energy',\n",
       " 'Construction',\n",
       " 'Retail.wholesale',\n",
       " 'Transport.warehousing',\n",
       " 'Hospitality.catering',\n",
       " 'Info.telecom',\n",
       " 'Finance.insurance',\n",
       " 'Real.estate',\n",
       " 'Research',\n",
       " 'Administrative',\n",
       " 'Civil.service.military',\n",
       " 'Education',\n",
       " 'Healthcare.social.help',\n",
       " 'Art.entertainment',\n",
       " 'Agriculture.for.fish',\n",
       " 'homeless',\n",
       " 'owner',\n",
       " 'livingw.parents',\n",
       " 'tenant.pfp',\n",
       " 'council.house',\n",
       " 'joint.tenant',\n",
       " 'joint.ownership',\n",
       " 'mortgage',\n",
       " 'encumbrance',\n",
       " 'no.liab.00',\n",
       " 'no.liab.01',\n",
       " 'no.liab.02',\n",
       " 'no.liab.03',\n",
       " 'no.liab.04',\n",
       " 'no.liab.05',\n",
       " 'no.liab.10',\n",
       " 'no.refin.00',\n",
       " 'no.refin.01',\n",
       " 'no.refin.02',\n",
       " 'no.refin.03',\n",
       " 'no.refin.04',\n",
       " 'no.previous.loan.00',\n",
       " 'no.previous.loan.01',\n",
       " 'no.previous.loan.02',\n",
       " 'no.previous.loan.03',\n",
       " 'no.previous.loan.04',\n",
       " 'no.previous.loan.05',\n",
       " 'no.previous.loan.06',\n",
       " 'no.previous.loan.07',\n",
       " 'no.previous.repay.00',\n",
       " 'no.previous.repay.01',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce95ae6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:10.276136Z",
     "start_time": "2023-06-29T18:35:10.272075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "959dcc84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:10.998924Z",
     "start_time": "2023-06-29T18:35:10.995555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(continuous_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "197fa921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:11.322118Z",
     "start_time": "2023-06-29T18:35:11.317774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(binary_columns)+len(continuous_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ce5af5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:11.786631Z",
     "start_time": "2023-06-29T18:35:11.783075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac72ab36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:12.421397Z",
     "start_time": "2023-06-29T18:35:12.411262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hour.0</th>\n",
       "      <th>Hour.1</th>\n",
       "      <th>Hour.2</th>\n",
       "      <th>Hour.3</th>\n",
       "      <th>Hour.4</th>\n",
       "      <th>Hour.5</th>\n",
       "      <th>Hour.6</th>\n",
       "      <th>Hour.7</th>\n",
       "      <th>...</th>\n",
       "      <th>no.previous.loan.03</th>\n",
       "      <th>no.previous.loan.04</th>\n",
       "      <th>no.previous.loan.05</th>\n",
       "      <th>no.previous.loan.06</th>\n",
       "      <th>no.previous.loan.07</th>\n",
       "      <th>no.previous.repay.00</th>\n",
       "      <th>no.previous.repay.01</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   new  Gender  Hour.0  Hour.1  Hour.2  Hour.3  Hour.4  Hour.5  Hour.6  \\\n",
       "0    1       0       0       0       0       0       0       0       0   \n",
       "1    1       0       1       0       0       0       0       0       0   \n",
       "2    0       0       0       0       0       0       0       0       0   \n",
       "3    0       0       0       0       0       0       0       0       0   \n",
       "4    1       0       0       0       0       0       0       0       0   \n",
       "5    0       0       0       0       0       0       0       0       0   \n",
       "6    0       1       0       0       0       0       0       0       0   \n",
       "7    0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   Hour.7  ...  no.previous.loan.03  no.previous.loan.04  no.previous.loan.05  \\\n",
       "0       0  ...                    0                    0                    0   \n",
       "1       0  ...                    0                    0                    0   \n",
       "2       0  ...                    0                    1                    0   \n",
       "3       0  ...                    0                    0                    0   \n",
       "4       1  ...                    0                    0                    0   \n",
       "5       0  ...                    0                    0                    0   \n",
       "6       0  ...                    1                    0                    0   \n",
       "7       0  ...                    0                    0                    1   \n",
       "\n",
       "   no.previous.loan.06  no.previous.loan.07  no.previous.repay.00  \\\n",
       "0                    0                    0                     1   \n",
       "1                    0                    0                     1   \n",
       "2                    0                    0                     1   \n",
       "3                    0                    0                     0   \n",
       "4                    0                    0                     1   \n",
       "5                    1                    0                     1   \n",
       "6                    0                    0                     1   \n",
       "7                    0                    0                     1   \n",
       "\n",
       "   no.previous.repay.01  A  B  C  \n",
       "0                     0  0  0  1  \n",
       "1                     0  0  1  0  \n",
       "2                     0  0  1  0  \n",
       "3                     1  0  0  1  \n",
       "4                     0  0  1  0  \n",
       "5                     0  0  0  1  \n",
       "6                     0  0  0  0  \n",
       "7                     0  0  1  0  \n",
       "\n",
       "[8 rows x 134 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_features[binary_columns].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "900f7e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:13.272640Z",
     "start_time": "2023-06-29T18:35:13.255495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Interest</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>DebtToIncome</th>\n",
       "      <th>NoOfPreviousLoansBeforeLoan</th>\n",
       "      <th>AmountOfPreviousLoansBeforeLoan</th>\n",
       "      <th>time</th>\n",
       "      <th>log.amount</th>\n",
       "      <th>inc.princ.empl.l</th>\n",
       "      <th>inc.pension.l</th>\n",
       "      <th>...</th>\n",
       "      <th>inc.support</th>\n",
       "      <th>FreeCash.l</th>\n",
       "      <th>previous.repay.l</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>19.33</td>\n",
       "      <td>5.284117</td>\n",
       "      <td>58.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.670</td>\n",
       "      <td>8.221479</td>\n",
       "      <td>6.566672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.824721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.902073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078653e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>16.23</td>\n",
       "      <td>5.241324</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.373</td>\n",
       "      <td>8.840870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.976149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.410830e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>13.34</td>\n",
       "      <td>4.438525</td>\n",
       "      <td>43.85</td>\n",
       "      <td>4</td>\n",
       "      <td>12200.0</td>\n",
       "      <td>2.938</td>\n",
       "      <td>8.066208</td>\n",
       "      <td>6.692084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05848</td>\n",
       "      <td>5.416278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.396533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.701703e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>23.32</td>\n",
       "      <td>3.161247</td>\n",
       "      <td>7.58</td>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.505</td>\n",
       "      <td>6.606650</td>\n",
       "      <td>6.803505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.423815</td>\n",
       "      <td>6.398595</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.359868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.883548e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>18.45</td>\n",
       "      <td>4.771532</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034</td>\n",
       "      <td>6.862758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.029100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.762067e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>17.37</td>\n",
       "      <td>2.899221</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>5275.0</td>\n",
       "      <td>3.102</td>\n",
       "      <td>6.272877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.300762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.723409e-92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>10.17</td>\n",
       "      <td>5.250387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4455.0</td>\n",
       "      <td>3.033</td>\n",
       "      <td>8.578288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.901119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.147977e-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>15.44</td>\n",
       "      <td>2.724580</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>4.397</td>\n",
       "      <td>6.274762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.491077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.074464e-107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Interest  MonthlyPayment  DebtToIncome  NoOfPreviousLoansBeforeLoan  \\\n",
       "0   51     19.33        5.284117         58.48                            0   \n",
       "1   28     16.23        5.241324          0.00                            0   \n",
       "2   40     13.34        4.438525         43.85                            4   \n",
       "3   25     23.32        3.161247          7.58                            2   \n",
       "4   50     18.45        4.771532          0.00                            0   \n",
       "5   42     17.37        2.899221          0.00                            6   \n",
       "6   39     10.17        5.250387          0.00                            3   \n",
       "7   29     15.44        2.724580          0.00                            5   \n",
       "\n",
       "   AmountOfPreviousLoansBeforeLoan   time  log.amount  inc.princ.empl.l  \\\n",
       "0                              0.0  2.670    8.221479          6.566672   \n",
       "1                              0.0  4.373    8.840870          0.000000   \n",
       "2                          12200.0  2.938    8.066208          6.692084   \n",
       "3                           1100.0  2.505    6.606650          6.803505   \n",
       "4                              0.0  4.034    6.862758          0.000000   \n",
       "5                           5275.0  3.102    6.272877          0.000000   \n",
       "6                           4455.0  3.033    8.578288          0.000000   \n",
       "7                           4135.0  4.397    6.274762          0.000000   \n",
       "\n",
       "   inc.pension.l  ...  inc.support  FreeCash.l  previous.repay.l  pagerank  \\\n",
       "0            0.0  ...      0.00000    3.824721          0.000000  0.000023   \n",
       "1            0.0  ...      0.00000    0.000000          0.000000  0.000023   \n",
       "2            0.0  ...      0.05848    5.416278          0.000000  0.000023   \n",
       "3            0.0  ...      0.00000    6.423815          6.398595  0.000023   \n",
       "4            0.0  ...      0.00000    0.000000          0.000000  0.000023   \n",
       "5            0.0  ...      0.00000    0.000000          0.000000  0.000023   \n",
       "6            0.0  ...      0.00000    0.000000          0.000000  0.000023   \n",
       "7            0.0  ...      0.00000    0.000000          0.000000  0.000023   \n",
       "\n",
       "   betweenness  closeness  eigenvector      katz  authority            hub  \n",
       "0          0.0   8.902073          NaN  0.006453        0.0   2.078653e-22  \n",
       "1          0.0  15.976149          NaN  0.006453        0.0   2.410830e-83  \n",
       "2          0.0  13.396533          NaN  0.006453        0.0   6.701703e-47  \n",
       "3          0.0   7.359868          NaN  0.006453        0.0   3.883548e-67  \n",
       "4          0.0  26.029100          NaN  0.006453        0.0   1.762067e-95  \n",
       "5          0.0  13.300762          NaN  0.006453        0.0   4.723409e-92  \n",
       "6          0.0  23.901119          NaN  0.006453        0.0   4.147977e-59  \n",
       "7          0.0  22.491077          NaN  0.006453        0.0  2.074464e-107  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_features[continuous_columns].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338463c9",
   "metadata": {},
   "source": [
    "### Convert binary to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03e7dd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:14.684633Z",
     "start_time": "2023-06-29T18:35:14.637972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the convert_binary_to_categorical function\n",
    "data_categorical = convert_binary_to_categorical(data_all_features, binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9bf42fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:15.212607Z",
     "start_time": "2023-06-29T18:35:15.206691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "23995    0\n",
       "23996    1\n",
       "23997    1\n",
       "23998    0\n",
       "23999    0\n",
       "Name: new, Length: 24000, dtype: category\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical[binary_columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086a8b8",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23bf58cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:17.568631Z",
     "start_time": "2023-06-29T18:35:17.543276Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yil1/opt/anaconda3/envs/P2P/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:473: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/yil1/opt/anaconda3/envs/P2P/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:474: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# Fit the scaler to the continuous features in the entire dataset\n",
    "data_categorical[continuous_columns] = scaler.fit_transform(data_categorical[continuous_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "682bc805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:18.264602Z",
     "start_time": "2023-06-29T18:35:18.255497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: min = 0.0, max = 1.0\n",
      "Interest: min = 0.0, max = 1.0\n",
      "MonthlyPayment: min = 0.0, max = 1.0\n",
      "DebtToIncome: min = 0.0, max = 0.9999999999999999\n",
      "NoOfPreviousLoansBeforeLoan: min = 0.0, max = 1.0\n",
      "AmountOfPreviousLoansBeforeLoan: min = 0.0, max = 1.0\n",
      "time: min = 0.0, max = 1.0\n",
      "log.amount: min = 0.0, max = 1.0000000000000002\n",
      "inc.princ.empl.l: min = 0.0, max = 1.0\n",
      "inc.pension.l: min = 0.0, max = 0.9999999999999999\n",
      "inc.fam.all.l: min = 0.0, max = 1.0\n",
      "inc.soc.wel.l: min = 0.0, max = 1.0\n",
      "inc.leave.l: min = 0.0, max = 1.0\n",
      "inc.child.l: min = 0.0, max = 1.0\n",
      "inc.other.l: min = 0.0, max = 1.0\n",
      "inc.total: min = 0.0, max = 1.0\n",
      "liab.l: min = 0.0, max = 1.0\n",
      "inc.support: min = 0.0, max = 1.0\n",
      "FreeCash.l: min = 0.0, max = 1.0\n",
      "previous.repay.l: min = 0.0, max = 1.0\n",
      "pagerank: min = 0.0, max = 0.9999999999999999\n",
      "betweenness: min = 0.0, max = 0.9999999999999999\n",
      "closeness: min = 0.0, max = 1.0\n",
      "eigenvector: min = nan, max = nan\n",
      "katz: min = 0.0, max = 1.0\n",
      "authority: min = 0.0, max = 1.0\n",
      "hub: min = 0.0, max = 1.0\n"
     ]
    }
   ],
   "source": [
    "# compute min and max for each column\n",
    "for column in continuous_columns:\n",
    "    min_value = data_categorical[column].min()\n",
    "    max_value = data_categorical[column].max()\n",
    "    print(f\"{column}: min = {min_value}, max = {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb10478",
   "metadata": {},
   "source": [
    "## Set the target and feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bdc54ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:19.355146Z",
     "start_time": "2023-06-29T18:35:19.350103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'Age',\n",
       " 'Gender',\n",
       " 'Interest',\n",
       " 'MonthlyPayment',\n",
       " 'DebtToIncome',\n",
       " 'NoOfPreviousLoansBeforeLoan',\n",
       " 'AmountOfPreviousLoansBeforeLoan',\n",
       " 'time',\n",
       " 'Hour.0',\n",
       " 'Hour.1',\n",
       " 'Hour.2',\n",
       " 'Hour.3',\n",
       " 'Hour.4',\n",
       " 'Hour.5',\n",
       " 'Hour.6',\n",
       " 'Hour.7',\n",
       " 'Hour.8',\n",
       " 'Hour.9',\n",
       " 'Hour.10',\n",
       " 'Hour.11',\n",
       " 'Hour.12',\n",
       " 'Hour.13',\n",
       " 'Hour.14',\n",
       " 'Hour.15',\n",
       " 'Hour.16',\n",
       " 'Hour.17',\n",
       " 'Hour.18',\n",
       " 'Hour.19',\n",
       " 'Hour.20',\n",
       " 'Hour.21',\n",
       " 'Hour.22',\n",
       " 'weekday.1',\n",
       " 'weekday.2',\n",
       " 'weekday.3',\n",
       " 'weekday.4',\n",
       " 'weekday.5',\n",
       " 'weekday.6',\n",
       " 'ver.3',\n",
       " 'ver.4',\n",
       " 'log.amount',\n",
       " 'duration.06',\n",
       " 'duration.09',\n",
       " 'duration.12',\n",
       " 'duration.18',\n",
       " 'duration.24',\n",
       " 'duration.36',\n",
       " 'duration.48',\n",
       " 'duration.60',\n",
       " 'use.0',\n",
       " 'use.1',\n",
       " 'use.2',\n",
       " 'use.3',\n",
       " 'use.4',\n",
       " 'use.5',\n",
       " 'use.6',\n",
       " 'use.7',\n",
       " 'use.8',\n",
       " 'educ.2',\n",
       " 'educ.3',\n",
       " 'educ.4',\n",
       " 'educ.5',\n",
       " 'marital.1',\n",
       " 'marital.2',\n",
       " 'marital.3',\n",
       " 'marital.4',\n",
       " 'marital.5',\n",
       " 'depen.0',\n",
       " 'depen.1',\n",
       " 'depen.2',\n",
       " 'depen.3',\n",
       " 'depen.4',\n",
       " 'employ.2',\n",
       " 'employ.3',\n",
       " 'employ.4',\n",
       " 'employ.5',\n",
       " 'employ.6',\n",
       " 'em.dur.other',\n",
       " 'em.dur.ret',\n",
       " 'em.dur.trial',\n",
       " 'em.dur.1y',\n",
       " 'em.dur.2y',\n",
       " 'em.dur.3y',\n",
       " 'em.dur.4y',\n",
       " 'em.dur.5y',\n",
       " 'exper.02y',\n",
       " 'exper.05y',\n",
       " 'exper.10y',\n",
       " 'exper.15y',\n",
       " 'exper.25y',\n",
       " 'exper.25p',\n",
       " 'Other',\n",
       " 'Processing',\n",
       " 'Energy',\n",
       " 'Construction',\n",
       " 'Retail.wholesale',\n",
       " 'Transport.warehousing',\n",
       " 'Hospitality.catering',\n",
       " 'Info.telecom',\n",
       " 'Finance.insurance',\n",
       " 'Real.estate',\n",
       " 'Research',\n",
       " 'Administrative',\n",
       " 'Civil.service.military',\n",
       " 'Education',\n",
       " 'Healthcare.social.help',\n",
       " 'Art.entertainment',\n",
       " 'Agriculture.for.fish',\n",
       " 'homeless',\n",
       " 'owner',\n",
       " 'livingw.parents',\n",
       " 'tenant.pfp',\n",
       " 'council.house',\n",
       " 'joint.tenant',\n",
       " 'joint.ownership',\n",
       " 'mortgage',\n",
       " 'encumbrance',\n",
       " 'inc.princ.empl.l',\n",
       " 'inc.pension.l',\n",
       " 'inc.fam.all.l',\n",
       " 'inc.soc.wel.l',\n",
       " 'inc.leave.l',\n",
       " 'inc.child.l',\n",
       " 'inc.other.l',\n",
       " 'inc.total',\n",
       " 'no.liab.00',\n",
       " 'no.liab.01',\n",
       " 'no.liab.02',\n",
       " 'no.liab.03',\n",
       " 'no.liab.04',\n",
       " 'no.liab.05',\n",
       " 'no.liab.10',\n",
       " 'liab.l',\n",
       " 'no.refin.00',\n",
       " 'no.refin.01',\n",
       " 'no.refin.02',\n",
       " 'no.refin.03',\n",
       " 'no.refin.04',\n",
       " 'inc.support',\n",
       " 'FreeCash.l',\n",
       " 'no.previous.loan.00',\n",
       " 'no.previous.loan.01',\n",
       " 'no.previous.loan.02',\n",
       " 'no.previous.loan.03',\n",
       " 'no.previous.loan.04',\n",
       " 'no.previous.loan.05',\n",
       " 'no.previous.loan.06',\n",
       " 'no.previous.loan.07',\n",
       " 'no.previous.repay.00',\n",
       " 'no.previous.repay.01',\n",
       " 'previous.repay.l',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'pagerank',\n",
       " 'betweenness',\n",
       " 'closeness',\n",
       " 'eigenvector',\n",
       " 'katz',\n",
       " 'authority',\n",
       " 'hub']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the target and feature columns:\n",
    "target_column = \"default\"\n",
    "feature_columns = [col for col in data_categorical.columns if col != target_column]\n",
    "feature_columns\n",
    "#target_column: y\n",
    "#feature_columns: X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc0f0c",
   "metadata": {},
   "source": [
    "## Write the preprocessed data (pandas data frame) to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07fe61f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:29.251896Z",
     "start_time": "2023-06-29T18:35:28.582760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/pandas_washes_preprocessed_shuffled'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_df_to_disk(data_categorical,\n",
    "                 directory=data_directory,\n",
    "                 filename=preprocessed_filename,\n",
    "                 parameters=parameter_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6320d41b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:31.691726Z",
     "start_time": "2023-06-29T18:35:31.687427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/b_i_n_a_r_y_ _c_o_l_u_m_n_s_preprocessed_shuffled'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_list_to_disk(lst = binary_columns, \n",
    "                   directory = data_directory, \n",
    "                   filename = preprocessed_filename, \n",
    "                   parameters = \"binary columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d0b9e",
   "metadata": {},
   "source": [
    "In previous section, we have:\n",
    "1. data_categorical: a pandas.core.frame.DataFrame, [5 rows x 162 columns] All binary columns converted to binary varibals, all continuous columns ranged to [0, 1];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811212c0",
   "metadata": {},
   "source": [
    "## Add robustness check columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea98a9b",
   "metadata": {},
   "source": [
    "### Generate necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c03a9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:33.372073Z",
     "start_time": "2023-06-29T18:35:33.367100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80179340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:34.033919Z",
     "start_time": "2023-06-29T18:35:34.026745Z"
    }
   },
   "outputs": [],
   "source": [
    "# last 7 columns\n",
    "shuffled_df = data_categorical.iloc[:, -7:].apply(np.random.permutation)\n",
    "\n",
    "# name\n",
    "shuffled_df.columns = [f\"{col}_shuffled\" for col in shuffled_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9469e8af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:34.815019Z",
     "start_time": "2023-06-29T18:35:34.802355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank_shuffled</th>\n",
       "      <th>betweenness_shuffled</th>\n",
       "      <th>closeness_shuffled</th>\n",
       "      <th>eigenvector_shuffled</th>\n",
       "      <th>katz_shuffled</th>\n",
       "      <th>authority_shuffled</th>\n",
       "      <th>hub_shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.322362e-126</td>\n",
       "      <td>3.894498e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.912055e-145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047385</td>\n",
       "      <td>2.070558e-93</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.958060e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.434134e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.032291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>4.330217e-90</td>\n",
       "      <td>2.214874e-123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.021081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.532707e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053730</td>\n",
       "      <td>3.209247e-97</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054821</td>\n",
       "      <td>4.160623e-149</td>\n",
       "      <td>1.543706e-108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>0.133452</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pagerank_shuffled  betweenness_shuffled  closeness_shuffled  \\\n",
       "0               0.000000              0.000000            0.025951   \n",
       "1               0.000000              0.048387            0.001409   \n",
       "2               0.016790              0.000000            0.010875   \n",
       "3               0.000000              0.000000            0.040460   \n",
       "4               0.000000              0.000000                 NaN   \n",
       "...                  ...                   ...                 ...   \n",
       "23995           0.032291              0.000000                 NaN   \n",
       "23996           0.021081              0.000000                 NaN   \n",
       "23997           0.000000              0.000000            0.025636   \n",
       "23998           0.000000              0.000000                 NaN   \n",
       "23999           0.133452              0.016129                 NaN   \n",
       "\n",
       "       eigenvector_shuffled  katz_shuffled  authority_shuffled   hub_shuffled  \n",
       "0                       NaN       0.000000       6.322362e-126   3.894498e-44  \n",
       "1                       NaN       0.000000        0.000000e+00  6.912055e-145  \n",
       "2                       NaN       0.047385        2.070558e-93   0.000000e+00  \n",
       "3                       NaN       0.018428        0.000000e+00   1.958060e-51  \n",
       "4                       NaN       0.000000        0.000000e+00   1.434134e-73  \n",
       "...                     ...            ...                 ...            ...  \n",
       "23995                   NaN       0.033967        4.330217e-90  2.214874e-123  \n",
       "23996                   NaN       0.000000        0.000000e+00   7.532707e-68  \n",
       "23997                   NaN       0.053730        3.209247e-97   0.000000e+00  \n",
       "23998                   NaN       0.054821       4.160623e-149  1.543706e-108  \n",
       "23999                   NaN       0.064236        0.000000e+00   0.000000e+00  \n",
       "\n",
       "[24000 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56829cad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:35.758299Z",
     "start_time": "2023-06-29T18:35:35.746726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.310865e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.319365e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.034661e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.179059e-66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.349700e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.308981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057166</td>\n",
       "      <td>6.773532e-103</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.162980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>3.405339e-142</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.477304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>6.427614e-126</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022996</td>\n",
       "      <td>4.560141e-49</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>0.319385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.165173e-80</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pagerank  betweenness  closeness  eigenvector      katz      authority  \\\n",
       "0      0.000000          0.0   0.007806          NaN  0.000000   0.000000e+00   \n",
       "1      0.000000          0.0   0.018536          NaN  0.000000   0.000000e+00   \n",
       "2      0.000000          0.0   0.014623          NaN  0.000000   0.000000e+00   \n",
       "3      0.000000          0.0   0.005467          NaN  0.000000   0.000000e+00   \n",
       "4      0.000000          0.0   0.033785          NaN  0.000000   0.000000e+00   \n",
       "...         ...          ...        ...          ...       ...            ...   \n",
       "23995  0.308981          0.0        NaN          NaN  0.057166  6.773532e-103   \n",
       "23996  0.162980          0.0        NaN          NaN  0.019803  3.405339e-142   \n",
       "23997  0.477304          0.0        NaN          NaN  0.036727  6.427614e-126   \n",
       "23998  0.031333          0.0        NaN          NaN  0.022996   4.560141e-49   \n",
       "23999  0.319385          0.0        NaN          NaN  0.049707   1.165173e-80   \n",
       "\n",
       "                hub  \n",
       "0      6.310865e-22  \n",
       "1      7.319365e-83  \n",
       "2      2.034661e-46  \n",
       "3      1.179059e-66  \n",
       "4      5.349700e-95  \n",
       "...             ...  \n",
       "23995  0.000000e+00  \n",
       "23996  0.000000e+00  \n",
       "23997  0.000000e+00  \n",
       "23998  0.000000e+00  \n",
       "23999  0.000000e+00  \n",
       "\n",
       "[24000 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical.iloc[:, -7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d80fa04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:39.337569Z",
     "start_time": "2023-06-29T18:35:39.334290Z"
    }
   },
   "outputs": [],
   "source": [
    "# filename we give for storing the preprocessed data, just before training\n",
    "preprocessed_filename = \"preprocessed_shuffled\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87bffe02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:39.819615Z",
     "start_time": "2023-06-29T18:35:39.812304Z"
    }
   },
   "outputs": [],
   "source": [
    "data_categorical = pd.concat([data_categorical, shuffled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a9e78f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:40.381350Z",
     "start_time": "2023-06-29T18:35:40.365982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>new</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Interest</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>DebtToIncome</th>\n",
       "      <th>NoOfPreviousLoansBeforeLoan</th>\n",
       "      <th>AmountOfPreviousLoansBeforeLoan</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "      <th>pagerank_shuffled</th>\n",
       "      <th>betweenness_shuffled</th>\n",
       "      <th>closeness_shuffled</th>\n",
       "      <th>eigenvector_shuffled</th>\n",
       "      <th>katz_shuffled</th>\n",
       "      <th>authority_shuffled</th>\n",
       "      <th>hub_shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392055</td>\n",
       "      <td>0.699456</td>\n",
       "      <td>0.834713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.310865e-22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.322362e-126</td>\n",
       "      <td>3.894498e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291110</td>\n",
       "      <td>0.693792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.319365e-83</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.912055e-145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197004</td>\n",
       "      <td>0.587526</td>\n",
       "      <td>0.625892</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.163233</td>\n",
       "      <td>0.370908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.034661e-46</td>\n",
       "      <td>0.01679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047385</td>\n",
       "      <td>2.070558e-93</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521980</td>\n",
       "      <td>0.418453</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.224772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.179059e-66</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.958060e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>0.631606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.349700e-95</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.434134e-73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   default new       Age Gender  Interest  MonthlyPayment  DebtToIncome  \\\n",
       "0        0   1  0.634615      0  0.392055        0.699456      0.834713   \n",
       "1        0   1  0.192308      0  0.291110        0.693792      0.000000   \n",
       "2        0   0  0.423077      0  0.197004        0.587526      0.625892   \n",
       "3        0   0  0.134615      0  0.521980        0.418453      0.108193   \n",
       "4        0   1  0.615385      0  0.363400        0.631606      0.000000   \n",
       "\n",
       "   NoOfPreviousLoansBeforeLoan  AmountOfPreviousLoansBeforeLoan      time  \\\n",
       "0                     0.000000                         0.000000  0.280459   \n",
       "1                     0.000000                         0.000000  0.855214   \n",
       "2                     0.153846                         0.163233  0.370908   \n",
       "3                     0.076923                         0.014718  0.224772   \n",
       "4                     0.000000                         0.000000  0.740803   \n",
       "\n",
       "   ... katz authority           hub pagerank_shuffled betweenness_shuffled  \\\n",
       "0  ...  0.0       0.0  6.310865e-22           0.00000             0.000000   \n",
       "1  ...  0.0       0.0  7.319365e-83           0.00000             0.048387   \n",
       "2  ...  0.0       0.0  2.034661e-46           0.01679             0.000000   \n",
       "3  ...  0.0       0.0  1.179059e-66           0.00000             0.000000   \n",
       "4  ...  0.0       0.0  5.349700e-95           0.00000             0.000000   \n",
       "\n",
       "  closeness_shuffled eigenvector_shuffled katz_shuffled authority_shuffled  \\\n",
       "0           0.025951                  NaN      0.000000      6.322362e-126   \n",
       "1           0.001409                  NaN      0.000000       0.000000e+00   \n",
       "2           0.010875                  NaN      0.047385       2.070558e-93   \n",
       "3           0.040460                  NaN      0.018428       0.000000e+00   \n",
       "4                NaN                  NaN      0.000000       0.000000e+00   \n",
       "\n",
       "    hub_shuffled  \n",
       "0   3.894498e-44  \n",
       "1  6.912055e-145  \n",
       "2   0.000000e+00  \n",
       "3   1.958060e-51  \n",
       "4   1.434134e-73  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4d7a70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:42.011831Z",
     "start_time": "2023-06-29T18:35:41.238699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/pandas_washes_preprocessed_shuffled'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_df_to_disk(data_categorical,\n",
    "                 directory=data_directory,\n",
    "                 filename=preprocessed_filename,\n",
    "                 parameters=parameter_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28071fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:42.628027Z",
     "start_time": "2023-06-29T18:35:42.622488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/b_i_n_a_r_y_ _c_o_l_u_m_n_s_preprocessed_shuffled'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_list_to_disk(lst = binary_columns, \n",
    "                   directory = data_directory, \n",
    "                   filename = preprocessed_filename, \n",
    "                   parameters = \"binary columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eefe46",
   "metadata": {},
   "source": [
    "# Read back and convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce091b4",
   "metadata": {},
   "source": [
    "## Read back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "764a0296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:44.497075Z",
     "start_time": "2023-06-29T18:35:44.345491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'Gender', 'Hour.0', 'Hour.1', 'Hour.2', 'Hour.3', 'Hour.4', 'Hour.5', 'Hour.6', 'Hour.7', 'Hour.8', 'Hour.9', 'Hour.10', 'Hour.11', 'Hour.12', 'Hour.13', 'Hour.14', 'Hour.15', 'Hour.16', 'Hour.17', 'Hour.18', 'Hour.19', 'Hour.20', 'Hour.21', 'Hour.22', 'weekday.1', 'weekday.2', 'weekday.3', 'weekday.4', 'weekday.5', 'weekday.6', 'ver.3', 'ver.4', 'duration.06', 'duration.09', 'duration.12', 'duration.18', 'duration.24', 'duration.36', 'duration.48', 'duration.60', 'use.0', 'use.1', 'use.2', 'use.3', 'use.4', 'use.5', 'use.6', 'use.7', 'use.8', 'educ.2', 'educ.3', 'educ.4', 'educ.5', 'marital.1', 'marital.2', 'marital.3', 'marital.4', 'marital.5', 'depen.0', 'depen.1', 'depen.2', 'depen.3', 'depen.4', 'employ.2', 'employ.3', 'employ.4', 'employ.5', 'employ.6', 'em.dur.other', 'em.dur.ret', 'em.dur.trial', 'em.dur.1y', 'em.dur.2y', 'em.dur.3y', 'em.dur.4y', 'em.dur.5y', 'exper.02y', 'exper.05y', 'exper.10y', 'exper.15y', 'exper.25y', 'exper.25p', 'Other', 'Processing', 'Energy', 'Construction', 'Retail.wholesale', 'Transport.warehousing', 'Hospitality.catering', 'Info.telecom', 'Finance.insurance', 'Real.estate', 'Research', 'Administrative', 'Civil.service.military', 'Education', 'Healthcare.social.help', 'Art.entertainment', 'Agriculture.for.fish', 'homeless', 'owner', 'livingw.parents', 'tenant.pfp', 'council.house', 'joint.tenant', 'joint.ownership', 'mortgage', 'encumbrance', 'no.liab.00', 'no.liab.01', 'no.liab.02', 'no.liab.03', 'no.liab.04', 'no.liab.05', 'no.liab.10', 'no.refin.00', 'no.refin.01', 'no.refin.02', 'no.refin.03', 'no.refin.04', 'no.previous.loan.00', 'no.previous.loan.01', 'no.previous.loan.02', 'no.previous.loan.03', 'no.previous.loan.04', 'no.previous.loan.05', 'no.previous.loan.06', 'no.previous.loan.07', 'no.previous.repay.00', 'no.previous.repay.01', 'A', 'B', 'C']\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "data_categorical = read_df_from_disk(directory = data_directory,\n",
    "                                     filename = preprocessed_filename, \n",
    "                                     parameters = parameter_string)\n",
    "binary_columns = read_list_from_disk(directory = data_directory,\n",
    "                                     filename = preprocessed_filename, \n",
    "                                     parameters = \"binary columns\")\n",
    "target_column = \"default\"\n",
    "feature_columns = [col for col in data_categorical.columns if col != target_column]\n",
    "print(binary_columns)\n",
    "print(len(binary_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4337cd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:44.951461Z",
     "start_time": "2023-06-29T18:35:44.944756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   default  new       Age  Gender  Interest  MonthlyPayment  DebtToIncome  \\\n",
      "0        0    1  0.634615       0  0.392055        0.699456      0.834713   \n",
      "1        0    1  0.192308       0  0.291110        0.693792      0.000000   \n",
      "2        0    0  0.423077       0  0.197004        0.587526      0.625892   \n",
      "3        0    0  0.134615       0  0.521980        0.418453      0.108193   \n",
      "4        0    1  0.615385       0  0.363400        0.631606      0.000000   \n",
      "\n",
      "   NoOfPreviousLoansBeforeLoan  AmountOfPreviousLoansBeforeLoan      time  \\\n",
      "0                     0.000000                         0.000000  0.280459   \n",
      "1                     0.000000                         0.000000  0.855214   \n",
      "2                     0.153846                         0.163233  0.370908   \n",
      "3                     0.076923                         0.014718  0.224772   \n",
      "4                     0.000000                         0.000000  0.740803   \n",
      "\n",
      "   ...  katz  authority           hub  pagerank_shuffled  \\\n",
      "0  ...   0.0        0.0  6.310865e-22            0.00000   \n",
      "1  ...   0.0        0.0  7.319365e-83            0.00000   \n",
      "2  ...   0.0        0.0  2.034661e-46            0.01679   \n",
      "3  ...   0.0        0.0  1.179059e-66            0.00000   \n",
      "4  ...   0.0        0.0  5.349700e-95            0.00000   \n",
      "\n",
      "   betweenness_shuffled  closeness_shuffled  eigenvector_shuffled  \\\n",
      "0              0.000000            0.025951                   NaN   \n",
      "1              0.048387            0.001409                   NaN   \n",
      "2              0.000000            0.010875                   NaN   \n",
      "3              0.000000            0.040460                   NaN   \n",
      "4              0.000000                 NaN                   NaN   \n",
      "\n",
      "   katz_shuffled  authority_shuffled   hub_shuffled  \n",
      "0       0.000000       6.322362e-126   3.894498e-44  \n",
      "1       0.000000        0.000000e+00  6.912055e-145  \n",
      "2       0.047385        2.070558e-93   0.000000e+00  \n",
      "3       0.018428        0.000000e+00   1.958060e-51  \n",
      "4       0.000000        0.000000e+00   1.434134e-73  \n",
      "\n",
      "[5 rows x 169 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(24000, 169)\n"
     ]
    }
   ],
   "source": [
    "print(data_categorical.head())\n",
    "print(type(data_categorical))\n",
    "print(data_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642703a4",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52d5b8a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:46.144450Z",
     "start_time": "2023-06-29T18:35:46.099414Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_categorical.drop(target_column, axis=1)\n",
    "y = data_categorical[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93b20cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:46.518788Z",
     "start_time": "2023-06-29T18:35:46.515989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 168)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51bcd4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:46.973326Z",
     "start_time": "2023-06-29T18:35:46.970207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 168)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "301017ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:47.402323Z",
     "start_time": "2023-06-29T18:35:47.399934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 168)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dc35022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:47.846501Z",
     "start_time": "2023-06-29T18:35:47.833981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "      <th>pagerank_shuffled</th>\n",
       "      <th>betweenness_shuffled</th>\n",
       "      <th>closeness_shuffled</th>\n",
       "      <th>eigenvector_shuffled</th>\n",
       "      <th>katz_shuffled</th>\n",
       "      <th>authority_shuffled</th>\n",
       "      <th>hub_shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.450147e-94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>8.897694e-77</td>\n",
       "      <td>6.282860e-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.836651e-95</td>\n",
       "      <td>0.072116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.237512e-44</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.523836e-52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>5.736236e-95</td>\n",
       "      <td>3.672094e-121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20503</th>\n",
       "      <td>0</td>\n",
       "      <td>0.205827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076921</td>\n",
       "      <td>7.045160e-87</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.754861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.493049e-61</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>1</td>\n",
       "      <td>0.317804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106411</td>\n",
       "      <td>5.334708e-83</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.118575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.263573e-62</td>\n",
       "      <td>2.982453e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.126107e-87</td>\n",
       "      <td>0.046740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>6.132651e-37</td>\n",
       "      <td>3.338669e-102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.096428e-58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024834e-65</td>\n",
       "      <td>4.944755e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095726</td>\n",
       "      <td>6.009113e-56</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>1</td>\n",
       "      <td>0.123723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>4.326897e-73</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.308121e-77</td>\n",
       "      <td>6.026703e-77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  pagerank  betweenness  closeness  eigenvector      katz  \\\n",
       "8063   1  0.000000          0.0   0.032052          NaN  0.000000   \n",
       "4812   0  0.000000          0.0   0.027383          NaN  0.000000   \n",
       "2126   1  0.000000          0.0   0.001437          NaN  0.000000   \n",
       "20503  0  0.205827          0.0        NaN          NaN  0.076921   \n",
       "15863  0  0.000000          0.0   0.014420          NaN  0.000000   \n",
       "...   ..       ...          ...        ...          ...       ...   \n",
       "21575  1  0.317804          0.0        NaN          NaN  0.106411   \n",
       "5390   0  0.000000          0.0   0.035732          NaN  0.000000   \n",
       "860    1  0.000000          0.0   0.036884          NaN  0.000000   \n",
       "15795  1  0.069807          0.0        NaN          NaN  0.095726   \n",
       "23654  1  0.123723          0.0        NaN          NaN  0.046349   \n",
       "\n",
       "          authority           hub  pagerank_shuffled  betweenness_shuffled  \\\n",
       "8063   0.000000e+00  1.450147e-94           0.000000                   0.0   \n",
       "4812   0.000000e+00  6.836651e-95           0.072116                   0.0   \n",
       "2126   0.000000e+00  1.523836e-52           0.000000                   0.0   \n",
       "20503  7.045160e-87  0.000000e+00           0.754861                   0.0   \n",
       "15863  0.000000e+00  2.493049e-61           0.025147                   0.0   \n",
       "...             ...           ...                ...                   ...   \n",
       "21575  5.334708e-83  0.000000e+00           0.118575                   0.0   \n",
       "5390   0.000000e+00  2.126107e-87           0.046740                   0.0   \n",
       "860    0.000000e+00  1.096428e-58           0.000000                   0.0   \n",
       "15795  6.009113e-56  0.000000e+00           0.170213                   0.0   \n",
       "23654  4.326897e-73  0.000000e+00           0.028315                   0.0   \n",
       "\n",
       "       closeness_shuffled  eigenvector_shuffled  katz_shuffled  \\\n",
       "8063                  NaN                   NaN       0.032320   \n",
       "4812             0.008196                   NaN       0.000000   \n",
       "2126             0.018443                   NaN       0.018299   \n",
       "20503            0.040617                   NaN       0.000000   \n",
       "15863            0.046317                   NaN       0.000000   \n",
       "...                   ...                   ...            ...   \n",
       "21575                 NaN                   NaN       0.000000   \n",
       "5390             0.069236                   NaN       0.019816   \n",
       "860              0.026148                   NaN       0.000000   \n",
       "15795                 NaN                   NaN       0.019335   \n",
       "23654            0.043040                   NaN       0.000000   \n",
       "\n",
       "       authority_shuffled   hub_shuffled  \n",
       "8063         8.897694e-77   6.282860e-93  \n",
       "4812         3.237512e-44   0.000000e+00  \n",
       "2126         5.736236e-95  3.672094e-121  \n",
       "20503        0.000000e+00   0.000000e+00  \n",
       "15863        0.000000e+00   0.000000e+00  \n",
       "...                   ...            ...  \n",
       "21575        1.263573e-62   2.982453e-29  \n",
       "5390         6.132651e-37  3.338669e-102  \n",
       "860          1.024834e-65   4.944755e-77  \n",
       "15795        0.000000e+00   0.000000e+00  \n",
       "23654        3.308121e-77   6.026703e-77  \n",
       "\n",
       "[14400 rows x 15 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.copy().iloc[:,-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed18f7",
   "metadata": {},
   "source": [
    "## Convert to H20\n",
    "also some simple tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbda995d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:51.398375Z",
     "start_time": "2023-06-29T18:35:48.815261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "X_train = convert_to_h2o_frame(X_train, binary_columns)\n",
    "X_test = convert_to_h2o_frame(X_test, binary_columns)\n",
    "X_val = convert_to_h2o_frame(X_val, binary_columns)\n",
    "\n",
    "y_train = convert_to_h2o_frame(y_train, 'default')\n",
    "y_test = convert_to_h2o_frame(y_test, 'default')\n",
    "y_val = convert_to_h2o_frame(y_val, 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "159a79c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:35:53.328542Z",
     "start_time": "2023-06-29T18:35:53.115637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n",
      "[True]\n",
      "[True]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.isfactor())\n",
    "print(y_train.isfactor())\n",
    "print(y_val.isfactor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5ba51d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:36:00.112977Z",
     "start_time": "2023-06-29T18:35:56.679675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column new is categorical\n",
      "Column Age is not categorical\n",
      "Column Gender is categorical\n",
      "Column Interest is not categorical\n",
      "Column MonthlyPayment is not categorical\n",
      "Column DebtToIncome is not categorical\n",
      "Column NoOfPreviousLoansBeforeLoan is not categorical\n",
      "Column AmountOfPreviousLoansBeforeLoan is not categorical\n",
      "Column time is not categorical\n",
      "Column Hour.0 is categorical\n",
      "Column Hour.1 is categorical\n",
      "Column Hour.2 is categorical\n",
      "Column Hour.3 is categorical\n",
      "Column Hour.4 is categorical\n",
      "Column Hour.5 is categorical\n",
      "Column Hour.6 is categorical\n",
      "Column Hour.7 is categorical\n",
      "Column Hour.8 is categorical\n",
      "Column Hour.9 is categorical\n",
      "Column Hour.10 is categorical\n",
      "Column Hour.11 is categorical\n",
      "Column Hour.12 is categorical\n",
      "Column Hour.13 is categorical\n",
      "Column Hour.14 is categorical\n",
      "Column Hour.15 is categorical\n",
      "Column Hour.16 is categorical\n",
      "Column Hour.17 is categorical\n",
      "Column Hour.18 is categorical\n",
      "Column Hour.19 is categorical\n",
      "Column Hour.20 is categorical\n",
      "Column Hour.21 is categorical\n",
      "Column Hour.22 is categorical\n",
      "Column weekday.1 is categorical\n",
      "Column weekday.2 is categorical\n",
      "Column weekday.3 is categorical\n",
      "Column weekday.4 is categorical\n",
      "Column weekday.5 is categorical\n",
      "Column weekday.6 is categorical\n",
      "Column ver.3 is categorical\n",
      "Column ver.4 is categorical\n",
      "Column log.amount is not categorical\n",
      "Column duration.06 is categorical\n",
      "Column duration.09 is categorical\n",
      "Column duration.12 is categorical\n",
      "Column duration.18 is categorical\n",
      "Column duration.24 is categorical\n",
      "Column duration.36 is categorical\n",
      "Column duration.48 is categorical\n",
      "Column duration.60 is categorical\n",
      "Column use.0 is categorical\n",
      "Column use.1 is categorical\n",
      "Column use.2 is categorical\n",
      "Column use.3 is categorical\n",
      "Column use.4 is categorical\n",
      "Column use.5 is categorical\n",
      "Column use.6 is categorical\n",
      "Column use.7 is categorical\n",
      "Column use.8 is categorical\n",
      "Column educ.2 is categorical\n",
      "Column educ.3 is categorical\n",
      "Column educ.4 is categorical\n",
      "Column educ.5 is categorical\n",
      "Column marital.1 is categorical\n",
      "Column marital.2 is categorical\n",
      "Column marital.3 is categorical\n",
      "Column marital.4 is categorical\n",
      "Column marital.5 is categorical\n",
      "Column depen.0 is categorical\n",
      "Column depen.1 is categorical\n",
      "Column depen.2 is categorical\n",
      "Column depen.3 is categorical\n",
      "Column depen.4 is categorical\n",
      "Column employ.2 is categorical\n",
      "Column employ.3 is categorical\n",
      "Column employ.4 is categorical\n",
      "Column employ.5 is categorical\n",
      "Column employ.6 is categorical\n",
      "Column em.dur.other is categorical\n",
      "Column em.dur.ret is categorical\n",
      "Column em.dur.trial is categorical\n",
      "Column em.dur.1y is categorical\n",
      "Column em.dur.2y is categorical\n",
      "Column em.dur.3y is categorical\n",
      "Column em.dur.4y is categorical\n",
      "Column em.dur.5y is categorical\n",
      "Column exper.02y is categorical\n",
      "Column exper.05y is categorical\n",
      "Column exper.10y is categorical\n",
      "Column exper.15y is categorical\n",
      "Column exper.25y is categorical\n",
      "Column exper.25p is categorical\n",
      "Column Other is categorical\n",
      "Column Processing is categorical\n",
      "Column Energy is categorical\n",
      "Column Construction is categorical\n",
      "Column Retail.wholesale is categorical\n",
      "Column Transport.warehousing is categorical\n",
      "Column Hospitality.catering is categorical\n",
      "Column Info.telecom is categorical\n",
      "Column Finance.insurance is categorical\n",
      "Column Real.estate is categorical\n",
      "Column Research is categorical\n",
      "Column Administrative is categorical\n",
      "Column Civil.service.military is categorical\n",
      "Column Education is categorical\n",
      "Column Healthcare.social.help is categorical\n",
      "Column Art.entertainment is categorical\n",
      "Column Agriculture.for.fish is categorical\n",
      "Column homeless is categorical\n",
      "Column owner is categorical\n",
      "Column livingw.parents is categorical\n",
      "Column tenant.pfp is categorical\n",
      "Column council.house is categorical\n",
      "Column joint.tenant is categorical\n",
      "Column joint.ownership is categorical\n",
      "Column mortgage is categorical\n",
      "Column encumbrance is categorical\n",
      "Column inc.princ.empl.l is not categorical\n",
      "Column inc.pension.l is not categorical\n",
      "Column inc.fam.all.l is not categorical\n",
      "Column inc.soc.wel.l is not categorical\n",
      "Column inc.leave.l is not categorical\n",
      "Column inc.child.l is not categorical\n",
      "Column inc.other.l is not categorical\n",
      "Column inc.total is not categorical\n",
      "Column no.liab.00 is categorical\n",
      "Column no.liab.01 is categorical\n",
      "Column no.liab.02 is categorical\n",
      "Column no.liab.03 is categorical\n",
      "Column no.liab.04 is categorical\n",
      "Column no.liab.05 is categorical\n",
      "Column no.liab.10 is categorical\n",
      "Column liab.l is not categorical\n",
      "Column no.refin.00 is categorical\n",
      "Column no.refin.01 is categorical\n",
      "Column no.refin.02 is categorical\n",
      "Column no.refin.03 is categorical\n",
      "Column no.refin.04 is categorical\n",
      "Column inc.support is not categorical\n",
      "Column FreeCash.l is not categorical\n",
      "Column no.previous.loan.00 is categorical\n",
      "Column no.previous.loan.01 is categorical\n",
      "Column no.previous.loan.02 is categorical\n",
      "Column no.previous.loan.03 is categorical\n",
      "Column no.previous.loan.04 is categorical\n",
      "Column no.previous.loan.05 is categorical\n",
      "Column no.previous.loan.06 is categorical\n",
      "Column no.previous.loan.07 is categorical\n",
      "Column no.previous.repay.00 is categorical\n",
      "Column no.previous.repay.01 is categorical\n",
      "Column previous.repay.l is not categorical\n",
      "Column A is categorical\n",
      "Column B is categorical\n",
      "Column C is categorical\n",
      "Column pagerank is not categorical\n",
      "Column betweenness is not categorical\n",
      "Column closeness is not categorical\n",
      "Column eigenvector is categorical\n",
      "Column katz is not categorical\n",
      "Column authority is not categorical\n",
      "Column hub is not categorical\n",
      "Column pagerank_shuffled is not categorical\n",
      "Column betweenness_shuffled is not categorical\n",
      "Column closeness_shuffled is not categorical\n",
      "Column eigenvector_shuffled is categorical\n",
      "Column katz_shuffled is not categorical\n",
      "Column authority_shuffled is not categorical\n",
      "Column hub_shuffled is not categorical\n"
     ]
    }
   ],
   "source": [
    "is_categorical = X_train.isfactor()\n",
    "for column, is_cat in zip(X_train.columns, is_categorical):\n",
    "    print(f\"Column {column} is {'categorical' if is_cat else 'not categorical'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e862f6",
   "metadata": {},
   "source": [
    "Successfully converted!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "670c3288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T18:36:03.752814Z",
     "start_time": "2023-06-29T18:36:03.748973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h2o.frame.H2OFrame'>\n",
      "<class 'h2o.frame.H2OFrame'>\n",
      "<class 'h2o.frame.H2OFrame'>\n",
      "<class 'h2o.frame.H2OFrame'>\n",
      "<class 'h2o.frame.H2OFrame'>\n",
      "<class 'h2o.frame.H2OFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(X_val))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12867c4c",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91737213",
   "metadata": {},
   "source": [
    "## Select according to distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b0db600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:50:48.835253Z",
     "start_time": "2023-06-29T19:50:48.829198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/GitHub/P2P-Model-Bondora/graph/features_plot.pdf\n"
     ]
    }
   ],
   "source": [
    "features_plot = generate_file_path('graph/features_plot.pdf')\n",
    "print(features_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02f93d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T08:26:24.729851Z",
     "start_time": "2023-06-30T08:26:14.103672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column eigenvector only contains NaN values. Skipping...\n",
      "Warning: Column eigenvector_shuffled only contains NaN values. Skipping...\n"
     ]
    }
   ],
   "source": [
    "plot_histogram(df=X_train, file=features_plot, column=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c40ec80e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:54:38.284856Z",
     "start_time": "2023-06-29T19:54:38.280683Z"
    }
   },
   "outputs": [],
   "source": [
    "exclude_features_distribution = [\n",
    "    'inc.princ.empl.l', 'inc.pension.l', 'inc.fam.all.l', 'inc.soc.wel.l',\n",
    "    'inc.leave.l', 'inc.child.l', 'inc.other.l', 'eigenvector', 'authority',\n",
    "    'hub', 'eigenvector_shuffled', 'authority_shuffled', 'hub_shuffled'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "028d9ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:54:38.728416Z",
     "start_time": "2023-06-29T19:54:38.724363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/e_x_c_l_u_d_e___f_e_a_t_u_r_e_s___d_i_s_t_r_i_b_u_t_i_o_n_preprocessed_shuffled'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_list_to_disk(lst=exclude_features_distribution,\n",
    "                   directory=data_directory,\n",
    "                   filename=preprocessed_filename,\n",
    "                   parameters=\"exclude_features_distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec06f95",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe459e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:54:43.336567Z",
     "start_time": "2023-06-29T19:54:41.867403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['closeness',\n",
       " 'eigenvector',\n",
       " 'authority',\n",
       " 'hub',\n",
       " 'closeness_shuffled',\n",
       " 'eigenvector_shuffled',\n",
       " 'authority_shuffled',\n",
       " 'hub_shuffled',\n",
       " 'Hour.3',\n",
       " 'marital.5',\n",
       " 'depen.4',\n",
       " 'employ.2',\n",
       " 'employ.4',\n",
       " 'employ.6',\n",
       " 'em.dur.trial',\n",
       " 'Energy',\n",
       " 'Real.estate',\n",
       " 'Research',\n",
       " 'Administrative',\n",
       " 'Art.entertainment',\n",
       " 'inc.soc.wel.l',\n",
       " 'inc.leave.l',\n",
       " 'inc.total',\n",
       " 'no.refin.04',\n",
       " 'inc.support',\n",
       " 'betweenness',\n",
       " 'katz',\n",
       " 'betweenness_shuffled',\n",
       " 'katz_shuffled',\n",
       " 'FreeCash.l',\n",
       " 'no.previous.repay.01',\n",
       " 'inc.princ.empl.l',\n",
       " 'liab.l',\n",
       " 'no.previous.loan.00',\n",
       " 'employ.3',\n",
       " 'previous.repay.l',\n",
       " 'Interest',\n",
       " 'AmountOfPreviousLoansBeforeLoan',\n",
       " 'Hour.2',\n",
       " 'Hour.9',\n",
       " 'Hour.12',\n",
       " 'Hour.19',\n",
       " 'weekday.2',\n",
       " 'weekday.4',\n",
       " 'weekday.6',\n",
       " 'depen.0',\n",
       " 'depen.1',\n",
       " 'em.dur.trial',\n",
       " 'exper.10y',\n",
       " 'Construction',\n",
       " 'Hospitality.catering',\n",
       " 'Administrative',\n",
       " 'FreeCash.l',\n",
       " 'no.previous.repay.00',\n",
       " 'A',\n",
       " 'pagerank_shuffled']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_features_selectionMethod = exclude_feature(X=X_train, y=y_train)\n",
    "exclude_features_selectionMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "125f3674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:55:55.282107Z",
     "start_time": "2023-06-29T19:55:55.275328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hour.3',\n",
       " 'marital.5',\n",
       " 'depen.4',\n",
       " 'employ.2',\n",
       " 'employ.4',\n",
       " 'employ.6',\n",
       " 'em.dur.trial',\n",
       " 'Energy',\n",
       " 'Real.estate',\n",
       " 'Research',\n",
       " 'Administrative',\n",
       " 'Art.entertainment',\n",
       " 'inc.soc.wel.l',\n",
       " 'inc.leave.l',\n",
       " 'inc.total',\n",
       " 'no.refin.04',\n",
       " 'inc.support',\n",
       " 'FreeCash.l',\n",
       " 'no.previous.repay.01',\n",
       " 'inc.princ.empl.l',\n",
       " 'liab.l',\n",
       " 'no.previous.loan.00',\n",
       " 'employ.3',\n",
       " 'previous.repay.l',\n",
       " 'Interest',\n",
       " 'AmountOfPreviousLoansBeforeLoan',\n",
       " 'Hour.2',\n",
       " 'Hour.9',\n",
       " 'Hour.12',\n",
       " 'Hour.19',\n",
       " 'weekday.2',\n",
       " 'weekday.4',\n",
       " 'weekday.6',\n",
       " 'depen.0',\n",
       " 'depen.1',\n",
       " 'em.dur.trial',\n",
       " 'exper.10y',\n",
       " 'Construction',\n",
       " 'Hospitality.catering',\n",
       " 'Administrative',\n",
       " 'FreeCash.l',\n",
       " 'no.previous.repay.00',\n",
       " 'A']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_to_remove = [\n",
    "    'pagerank', 'betweenness', 'closeness', 'eigenvector', 'katz', 'authority',\n",
    "    'hub', 'pagerank_shuffled', 'betweenness_shuffled', 'closeness_shuffled',\n",
    "    'eigenvector_shuffled', 'katz_shuffled', 'authority_shuffled',\n",
    "    'hub_shuffled'\n",
    "]\n",
    "exclude_features_selectionMethod = [\n",
    "    feature for feature in exclude_features_selectionMethod\n",
    "    if feature not in elements_to_remove\n",
    "]\n",
    "exclude_features_selectionMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4905a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:57:36.995093Z",
     "start_time": "2023-06-29T19:57:36.990899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/data/e_x_c_l_u_d_e___f_e_a_t_u_r_e_s___s_e_l_e_c_t_i_o_n_M_e_t_h_o_d_preprocessed_shuffled'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_list_to_disk(lst=exclude_features_selectionMethod,\n",
    "                   directory=data_directory,\n",
    "                   filename=preprocessed_filename,\n",
    "                   parameters=\"exclude_features_selectionMethod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eda591",
   "metadata": {},
   "source": [
    "# Parameters 2: Parameters for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e3173",
   "metadata": {},
   "source": [
    "## Model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d45c271a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:01.095435Z",
     "start_time": "2023-06-29T19:56:01.092546Z"
    }
   },
   "outputs": [],
   "source": [
    "model_directory = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80b2ed",
   "metadata": {},
   "source": [
    "## Define models\n",
    "Add new models here.\n",
    "\n",
    "Mapping from model to model_id.\n",
    "\n",
    "Do not for get to import models in Section 2 at h20 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56bd8705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:02.787248Z",
     "start_time": "2023-06-29T19:56:02.781262Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Models and Hyperparameters\n",
    "\n",
    "This section defines a list of models along with their corresponding hyperparameters. Each model is represented by a dictionary containing the following keys:\n",
    "\n",
    "- 'model': The model class or constructor.\n",
    "- 'model_name': A string representing the name or identifier of the model.\n",
    "- 'hyper_params': A dictionary specifying the hyperparameter grid for the model.\n",
    "- 'params': Additional parameters for the model.\n",
    "\n",
    "The list 'models_and_hyperparams' contains multiple such dictionaries, each representing a different model with its hyperparameters.\n",
    "\n",
    "After defining the list, the function 'write_list_to_disk' is called to write the 'models_and_hyperparams' list to a file on disk.\n",
    "\n",
    "Parameters:\n",
    "- None\n",
    "\n",
    "Returns:\n",
    "- None\n",
    "\n",
    "Example Usage:\n",
    "Define the models and hyperparameters, and write them to a file:\n",
    "    write_list_to_disk(\n",
    "        lst=models_and_hyperparams,\n",
    "        directory=model_directory,\n",
    "        filename=\"models_and_hyperparams\",\n",
    "        parameters=\"\"\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# Define Models and Hyperparameters\n",
    "models_and_hyperparams = [\n",
    "    # Existing models...\n",
    "    {\n",
    "        'model': H2OGeneralizedLinearEstimator,\n",
    "        'model_name': \"GLM\",\n",
    "        'hyper_params': {\n",
    "            'alpha': [0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "            'lambda': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "        },\n",
    "        'params': {\n",
    "            'family': 'binomial'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': H2ORandomForestEstimator,\n",
    "        'model_name': \"RF\",\n",
    "        'hyper_params': {\n",
    "            'ntrees': [50, 100, 150, 200, 250],\n",
    "            'max_depth': [5, 10, 15, 20]\n",
    "        },\n",
    "        'params': {}\n",
    "    },\n",
    "    {\n",
    "        'model': H2ODeepLearningEstimator,\n",
    "        'model_name': \"DL\",\n",
    "        'hyper_params': {\n",
    "            'hidden': [[50, 50], [100, 100], [200, 200], [100, 200, 100],\n",
    "                       [200, 100, 200]],\n",
    "            'epochs': [10, 50, 100],\n",
    "        },\n",
    "        'params': {}\n",
    "    },\n",
    "    # New models...\n",
    "    {\n",
    "        'model': H2OXGBoostEstimator,\n",
    "        'model_name': \"XGB\",\n",
    "        'hyper_params': {\n",
    "            'ntrees': [100, 200],\n",
    "            'max_depth': [5, 15],\n",
    "            'learn_rate': [0.01, 0.1, 0.2],\n",
    "            'sample_rate': [0.6, 0.8, 1.0],\n",
    "        },\n",
    "        'params': {}\n",
    "    },\n",
    "    {\n",
    "        'model': H2OGradientBoostingEstimator,\n",
    "        'model_name': \"GBM\",\n",
    "        'hyper_params': {\n",
    "            'ntrees': [100, 200],\n",
    "            'max_depth': [5, 15],\n",
    "            'learn_rate': [0.01, 0.1, 0.2],\n",
    "            'sample_rate': [0.6, 0.8, 1.0],\n",
    "        },\n",
    "        'params': {}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e9e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T13:14:39.098261Z",
     "start_time": "2023-05-22T13:14:39.087414Z"
    }
   },
   "source": [
    "This cell is not very useful because an object can hardly be saved in right format. The current method is to copy this cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd077636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:04.668397Z",
     "start_time": "2023-06-29T19:56:04.664636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/GitHub/P2P-Model-Bondora/model/_models_and_hyperparams'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the models and hyperparameters to a file\n",
    "write_list_to_disk(\n",
    "    lst=models_and_hyperparams,\n",
    "    directory=model_directory,\n",
    "    filename=\"models_and_hyperparams\",\n",
    "    parameters=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d42ffab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:06.764817Z",
     "start_time": "2023-06-29T19:56:06.761047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model Mapping and Print Example\n",
    "\n",
    "This section defines a dictionary named 'model_mapping' that maps H2O model classes to their corresponding abbreviations or names. The keys in the dictionary are the model classes (e.g., H2OGeneralizedLinearEstimator) and the values are the corresponding abbreviations or names (e.g., \"GLM\").\n",
    "\n",
    "After defining the 'model_mapping' dictionary, an example print statement is used to demonstrate how to retrieve the abbreviation/name for a specific model class. In this case, the abbreviation/name for the H2OGeneralizedLinearEstimator class is retrieved and printed.\n",
    "\n",
    "Parameters:\n",
    "- None\n",
    "\n",
    "Returns:\n",
    "- None\n",
    "\n",
    "Example Usage:\n",
    "Define the 'model_mapping' dictionary and retrieve the abbreviation/name for a specific model class:\n",
    "    print(model_mapping[H2OGeneralizedLinearEstimator])\n",
    "\"\"\"\n",
    "\n",
    "# Model Mapping\n",
    "model_mapping = {\n",
    "    H2OGeneralizedLinearEstimator: \"GLM\",\n",
    "    H2ORandomForestEstimator: \"RF\",\n",
    "    H2ODeepLearningEstimator: \"DL\",\n",
    "    H2OXGBoostEstimator:\"XGB\",\n",
    "    H2OGradientBoostingEstimator:\"GBM\"\n",
    "}\n",
    "\n",
    "# Example Print Statement\n",
    "print(model_mapping[H2OGeneralizedLinearEstimator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ecc5cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:07.306829Z",
     "start_time": "2023-06-29T19:56:07.303600Z"
    }
   },
   "outputs": [],
   "source": [
    "if not len(models_and_hyperparams) == len(model_mapping):\n",
    "    print(\"Check your definition of models. Always keep consistent for the cells above!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa99658",
   "metadata": {},
   "source": [
    "## Choose model\n",
    "You can train only a some types of models by changing parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2704ba3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:26.836402Z",
     "start_time": "2023-06-29T19:56:26.832369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/GitHub/P2P-Model-Bondora/output_info/['GLM', 'RF', 'DL'].txt\n"
     ]
    }
   ],
   "source": [
    "model_to_train = [\"GLM\",'RF',\"DL\"]\n",
    "output_file=generate_file_path('output_info/'+str(model_to_train)+\".txt\")\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731b4ca",
   "metadata": {},
   "source": [
    "## Other parameters controling the training and saving process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a17f268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:11.904650Z",
     "start_time": "2023-06-29T19:56:11.901425Z"
    }
   },
   "outputs": [],
   "source": [
    "## Training parameters\n",
    "run_explanation = False # run model_explain , it is quite slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2347e",
   "metadata": {},
   "source": [
    "## Parameters for X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b7d40323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:56:21.128208Z",
     "start_time": "2023-06-29T19:56:21.123506Z"
    }
   },
   "outputs": [],
   "source": [
    "exclude_features_distribution\n",
    "exclude_features_selectionMethod\n",
    "\n",
    "exclude_LIST = [\n",
    "    #This is EXCLUDE list!!!\n",
    "    #When you change this list, it must keep two dimentions, and contains only strings\n",
    "    #All initial columns - uninformative features\n",
    "    list(\n",
    "        set([\n",
    "            'pagerank', 'betweenness', 'closeness', 'eigenvector', 'katz',\n",
    "            'authority', 'hub', 'pagerank_shuffled', 'betweenness_shuffled',\n",
    "            'closeness_shuffled', 'eigenvector_shuffled', 'katz_shuffled',\n",
    "            'authority_shuffled', 'hub_shuffled'\n",
    "        ] + exclude_features_distribution + exclude_features_selectionMethod)),\n",
    "    #Initial columns - uninformative features + informative graph features\n",
    "    list(\n",
    "        set([\n",
    "            'pagerank_shuffled', 'betweenness_shuffled', 'closeness_shuffled',\n",
    "            'eigenvector_shuffled', 'katz_shuffled', 'authority_shuffled',\n",
    "            'hub_shuffled'\n",
    "        ] + exclude_features_distribution + exclude_features_selectionMethod)),\n",
    "    #All initial columns - uninformative features\n",
    "    list(\n",
    "        set([\n",
    "            'pagerank', 'betweenness', 'closeness', 'eigenvector', 'katz',\n",
    "            'authority', 'hub', 'pagerank_shuffled', 'betweenness_shuffled',\n",
    "            'closeness_shuffled', 'eigenvector_shuffled', 'katz_shuffled',\n",
    "            'authority_shuffled', 'hub_shuffled'\n",
    "        ] + exclude_features_distribution + exclude_features_selectionMethod)),\n",
    "    #Initial columns - uninformative features + shuffled  graph features\n",
    "    list(\n",
    "        set([\n",
    "            'pagerank', 'betweenness', 'closeness', 'eigenvector', 'katz',\n",
    "            'authority', 'hub'\n",
    "        ] + exclude_features_distribution + exclude_features_selectionMethod))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3c364",
   "metadata": {},
   "source": [
    "Explaination on exclude list\n",
    "\n",
    "exclude_features_distribution:\\\n",
    "Features in this list are excluded because their distribution (observed from histogram) are not informative. Most observations take same value on these features. So they are manually picked up and deleted.\\\n",
    "Features in this list are not condidered in the whole process: model training, hypermeter tuning and so on.\n",
    "'eigenvector', 'authority','hub', 'eigenvector_shuffled', 'authority_shuffled', 'hub_shuffled' are in this list.\n",
    "\n",
    "exclude_features_selectionMethod:\n",
    "Features in this list are selected out by function exclude_feature(X, y). This function selects uninformative features if one feature:\\\n",
    "contains NaN values\\\n",
    "is constant or quasi-constant\\\n",
    "is highly correlated with another feature\\\n",
    "is independent to y according to the Chi-squared test.\\\n",
    "Features in this list are not condidered in the whole process: model training, hypermeter tuning and so on.\n",
    "\n",
    "Then, exclude_list 1 excludes all graph features and their shuffled value.\\\n",
    "This means the 1st group use all informative columns in initial data set.\n",
    "\n",
    "exclude_list 2 excludes all shuffled graph features.\\\n",
    "This means the 2nd group use all informative columns in initial data set, plus 4 graph features.\n",
    "\n",
    "exclude_list 3 is the same as exclude_list 1. This group is only for robustness check purpose.\n",
    "\n",
    "exclude_list 4 excludes all graph features.\\\n",
    "This means the 4th group use all informative columns in initial data set, plus 4 shuffled graph features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399b649",
   "metadata": {},
   "source": [
    "# Models: Training and Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b63e2",
   "metadata": {},
   "source": [
    "## Train the H20 model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d5a8bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:14:24.269407Z",
     "start_time": "2023-06-29T20:01:08.971541Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "drf Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "drf Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "drf Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning Grid Build progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning Grid Build progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning Grid Build progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "model_training_and_saving(X_train=X_train,\n",
    "                          X_val=X_val,\n",
    "                          y_train=y_train,\n",
    "                          y_val=y_val,\n",
    "                          exclude_LIST=exclude_LIST,\n",
    "                          models_and_hyperparams=models_and_hyperparams,\n",
    "                          model_to_train=model_to_train,\n",
    "                          model_directory=model_directory,\n",
    "                          run_explanation=run_explanation,\n",
    "                          output_filepath=output_file,\n",
    "                          print_training_info=False,\n",
    "                          force_return=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43d9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.725555px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
